I"#<p><em>Presentation of quality of embeddings documents available on my <a href="https://github.com/mbenhamd/documents-embeddings">Github repository</a></em>:</p>

<h1 id="abstract">Abstract</h1>

<p>Text Mining is a branch of Data Mining that specializes in
text corpus processing to analyze the content and extract it
knowledge. In our case, the objective is to evaluate the quality of a
set of embedding dies that represent documents. We
will perform a clustering on documents and will compare the values of
clustering with different evaluation criteria.</p>

<!--more-->

<h1 id="introduction">Introduction</h1>

<p>Paragraph vectors (Doc2Vec) have recently been proposed as
unsupervised method for learning documents. In their
works, the authors showed that the method can learn to integrate
Movie review texts that can be used for sentiment analysis. This proof of concept, while encouraging, was rather
narrow.
Indeed, the word embedding has opened new perspectives across
a reduction in dimensionality and a new vision of words (a
semantic vision).
In the same way the document embedding is an extension brought
when the number of documents becomes important and we seek to have
a result of similarity, then be able to classify and have a technique to discriminate documents (e.g., books of mechanics and
Botanical).
Here we consider tasks other than the analysis of feelings, we
use two datasets (Class3 and Reut8) with other analysis algorithms, such as the NMF and the LSA to evaluate the quality of
their embeddings. Then we will evaluate the performances to see
what are the strengths and weaknesses of the different analyzes.</p>

<h1 id="conclusion">Conclusion</h1>

<p>As part of this project we learned a lot about the methods
such as the LSA, NMF as well as Doc2Vec.
Each method seen in these projects has strong and weak points
like how fast the LSA does to Doc2Vec and the NMF, or
the ability of the NMF to have a decomposition taking into account the
weight of each cluster and thus to be more easily interpretable following
each column of the matrix W then the LSA had an ability to retrieve
the different meanings of the words.
Then we realized without real surprise that Doc2Vec was the method bringing the best results knowing that we can load a
pre-trained model on a very large dataset to be able to transfer
knowledge (in other words, initialize the weights of the neural network), this
which lets us think that this is a very promising method.
Doc2Vec appears as an ideal method in itself, even if they are
classic data sets, we could see that the defects of Reters8 were able to
to be exceeded by modifying the algorithm through the two approaches of this
method.
This project allowed us to use several popular python library,
with their lots of varieties and to be able to analyze and model our games of
data as well as learning in many ways.
We could have improved the results on the datasets by performing
further pre-processing, but the purpose of this project was rather to evaluate
quality in a general way without being specific according to the context of the
data.</p>
:ET