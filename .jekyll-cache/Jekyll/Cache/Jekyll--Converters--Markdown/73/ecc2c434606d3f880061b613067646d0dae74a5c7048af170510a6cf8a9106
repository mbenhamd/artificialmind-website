I"ï<p><img src="/ressources/ensemble-method/boxplot.png" alt="drawing" width="auto" max-width="100%" height="50%" />
<br /></p>

<p><em>Presentation of ensemble method applied to Detection of financial fraud available on my <a href="https://github.com/mbenhamd/methodes-ensemblistes-fraudes">Github repository</a></em>:</p>

<h6 id="abstract">Abstract</h6>

<p>Fraud represents a loss of turnover of several billion dollars and increases every year. The economic crime survey PwC global survey in 2018 revealed that half (49%) of the 7,200 respondents had been the victim of some type of fraud. Itâ€™s about of an increase over the 2016 PwC study in which a little more than one third of the organizations surveyed (36%) had been victims of economic crime. Traditional methods of data analysis have been used for a long time to detect fraud and it is in this context that we will carry out several ways to approach the problem in order to see the advantages and disadvantages of each learning model and the one that gives the best prediction results.
<!--more--></p>

<h6 id="introduction">Introduction</h6>

<p>Techniques used to detect fraud require investigation complex and tedious then they deal with different areas of knowledge such as finance, economics. Here are some examples of statistical data analysis techniques:</p>

<ul>
  <li>Pre-processing techniques for detecting, validating, correcting errors and filling missing data or incorrect.</li>
  <li>Calculation of various statistical parameters such as averages, quantiles, performance measures, probability distributions, etc.</li>
  <li>Chronological analysis of time-dependent data (time series).</li>
</ul>

<p><img src="/ressources/ensemble-method/features.png" alt="alt text" title="MNIST Sample" /></p>

<p>In our case, we will use models of supervised learning and we will not use clustering methods. This type of model only detects frauds similar to those that took place previously and were classified by a human. Regarding the detection of fraud by credit card payment, the problem of ranking involves the creation of sufficiently intelligent models to properly classify transactions into legitimate transactions or fraudulent, depending on the details of the transaction such as the amount, the trader, the location, the time and others.</p>

<h6 id="conclusion">Conclusion</h6>

<p>To conclude, we have been very interested in the set-up methods in our approach to this problem in order to be original. The decision tree-based methods are interesting because model architecture reduces over-fitting, but poor sampling practices can lead to misleading conclusions the quality of a model. The main purpose of model validation is to estimate how whose model will generalize to new data. If the decision to put a model in production depends on how it works on a validation set, it is essential that the oversampling be performed correctly. In fact, by oversampling only the training data, none of the information contained in the validation data is used to create synthetic observations therefore, these results should be generalizable. Then oversampling is a well-known way to potentially improve the models formed on unbalanced data but it is important to remember that incorrect oversampling can lead to think that a model will generalize better than it actually does. Our results may seem weak compared to what is available on the internet but it is appropriate to use cross validation correctly with good sampling method as well as an appropriate metric when our data is out of balance.</p>
:ET