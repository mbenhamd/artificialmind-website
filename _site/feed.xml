<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Artificial Mind Blog.</title>
        <description>Welcome to my website, it covers a section regarding my vocation, but there are articles about my projects and some about new ideas in the field of artificial intelligence.</description>
        <link>http://localhost:4000/</link>
        <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
        <pubDate>Thu, 01 Oct 2020 16:04:20 +0100</pubDate>
        <lastBuildDate>Thu, 01 Oct 2020 16:04:20 +0100</lastBuildDate>
        <generator>Jekyll v4.1.1</generator>
        
            <item>
                <title>LOGAN: Latent Optimisation for Generative Adversarial Networks</title>
                <description>&lt;p&gt;&lt;img src=&quot;https://yt3.ggpht.com/a/AGF-l7-ncmSiLyMlXHexWBJfa61xH8Y02WWQbnI4rg=s900-c-k-c0xffffffff-no-rj-mo&quot; alt=&quot;drawing&quot; width=&quot;auto&quot; max-width=&quot;100%&quot; height=&quot;auto&quot; /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Presentation of a Paper avalaible &lt;a href=&quot;https://arxiv.org/pdf/1912.00953.pdf&quot;&gt;here&lt;/a&gt;&lt;/em&gt;:&lt;/p&gt;

&lt;p&gt;Training generative adversarial networks demand to match of dainty competitive dynamics. Yet by precise tuning, training may differ or end up in poor stability with dropped modes. In this work, they improved CS-GAN with natural gradient-based latent optimisation and confirm that it increases adversarial dynamics by intensifying interactions between the discriminator and the generator. Their experiments demonstrate that latent optimisation can significantly enhance GAN training, achieving state-of-the-art achievement for the ImageNet (128 × 128) dataset. Their model achieves an Inception Score (IS) of 148 and an Fréchet Inception Distance (FID) of 3.4, an enhancement of 17% and 32% in IS and FID individually, confronted with the baseline BigGAN-deep model with the same architecture and number of parameters.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h5 id=&quot;introduction&quot;&gt;Introduction&lt;/h5&gt;

&lt;p&gt;Generative Adversarial Nets (GANs) are inherent generative models that can be trained to satisfy a provided data distribution. GANs was basically stated by Goodfellow et al. (2014) for image data.
As the field of generative modelling has progressed, GANs rest at the edge, generating high fidelity images at massive scale. Nonetheless, despite increasing insights within the dynamics of GAN training, much of the progress in GAN-based image generation happens from network architecture improvements or regularisation of distinct parts of the model.&lt;/p&gt;

&lt;h6 id=&quot;what-do-they-propose&quot;&gt;What do they propose&lt;/h6&gt;

&lt;p&gt;They used standard BigGAN-deep architecture with three minor alterations:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;They extended the size of the latent source from 128 to 256, to compensate the randomness of the source lost when optimising the latent variable.&lt;/li&gt;
  &lt;li&gt;They used the uniform distribution U(−1, 1) rather than the standard average distribution N(0, 1) for p(z) to be consistent with the clipping operation.&lt;/li&gt;
  &lt;li&gt;They used leaky ReLU (with the slope of 0.2 for the negative part) instead of ReLU as the non-linearity for smoother gradient flow consistent with the detailed findings in this paper, their experiment with this baseline model obtains only slightly better scores compared with those here:&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;They computed the FID and IS as in this paper, and calculated IS values from checkpoints with the lowest FIDs.&lt;/p&gt;

&lt;p&gt;Finally, they calculated the means and standard deviations for both measures from 5 models with different random seeds.
To apply latent optimisation with NGD, they used the same large step size of α = 0.9 as in SN-GAN. However, we found much heavier damping is essential for BigGAN, so we use the damping factor β = 5.0, and only optimise 50% of z’s elements.&lt;/p&gt;

&lt;h5 id=&quot;contribution&quot;&gt;Contribution&lt;/h5&gt;

&lt;h5 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h5&gt;
&lt;p&gt;To review their enrichment:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;They propose an advanced, effective approach to latent optimisation using natural gradient descent.&lt;/li&gt;
  &lt;li&gt;Their algorithm increases the state-of-the-art BigGAN by a significant margin, without introducing any architectural change, resulting in more astonishing quality images and more different representations.&lt;/li&gt;
  &lt;li&gt;To provide theoretical insight, they analysed latent optimisation in GANs from the view of differentiable games. They argue that latent optimisation can be viewed as improving the dynamics of adversarial training.&lt;/li&gt;
&lt;/ol&gt;

</description>
                <pubDate>Wed, 11 Dec 2019 00:00:00 +0000</pubDate>
                <link>http://localhost:4000/latent-optimisation-generative-adversial-networks</link>
                <guid isPermaLink="true">http://localhost:4000/latent-optimisation-generative-adversial-networks</guid>
                
                <category>Reiforcement learning</category>
                
                <category>Associative memory</category>
                
                <category>Gradient-Based Meta-Learning</category>
                
                
            </item>
        
            <item>
                <title>Analyzing and Improving the Image Quality of StyleGAN</title>
                <description>&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1174/1*LgSQi3MLNE1l-T4vmjmybg.png&quot; alt=&quot;drawing&quot; width=&quot;auto&quot; max-width=&quot;100%&quot; height=&quot;auto&quot; /&gt;
&lt;br /&gt;
&lt;em&gt;Presentation of a Paper avalaible &lt;a href=&quot;https://arxiv.org/pdf/1912.04958.pdf&quot;&gt;here&lt;/a&gt;&lt;/em&gt;:&lt;/p&gt;

&lt;p&gt;The style-based GAN architecture (StyleGAN) yields
state-of-the-art results in data-driven unconditional generative image modeling. We expose and analyze several of
its characteristic artifacts, and propose changes in both
model architecture and training methods to address them.
In particular, we redesign the generator normalization, revisit progressive growing, and regularize the generator to
encourage good conditioning in the mapping from latent
codes to images. In addition to improving image quality,
this path length regularizer yields the additional benefit that
the generator becomes significantly easier to invert. This
makes it possible to reliably attribute a generated image to
a particular network. We furthermore visualize how well
the generator utilizes its output resolution, and identify a
capacity problem, motivating us to train larger models for
additional quality improvements. Overall, our improved
model redefines the state of the art in unconditional image
modeling, both in terms of existing distribution quality metrics as well as perceived image quality.
&lt;!--more--&gt;&lt;/p&gt;

&lt;h5 id=&quot;introduction&quot;&gt;Introduction&lt;/h5&gt;
&lt;p&gt;The resolution and quality of images produced by generative methods, especially generative adversarial networks
(GAN) [16], are improving rapidly [23, 31, 5]. The current
state-of-the-art method for high-resolution image synthesis
is StyleGAN [24], which has been shown to work reliably
on a variety of datasets. Our work focuses on fixing its characteristic artifacts and improving the result quality further.
The distinguishing feature of StyleGAN [24] is its unconventional generator architecture. Instead of feeding the
input latent code z ∈ Z only to the beginning of a the network, the mapping network f first transforms it to an intermediate latent code w ∈ W. Affine transforms then produce styles that control the layers of the synthesis network g
via adaptive instance normalization (AdaIN) [21, 9, 13, 8].
Additionally, stochastic variation is facilitated by providing
additional random noise maps to the synthesis network. It
has been demonstrated [24, 38] that this design allows the
intermediate latent space W to be much less entangled than
the input latent space Z. In this paper, we focus all analysis solely on W, as it is the relevant latent space from the
synthesis network’s point of view.&lt;/p&gt;
&lt;h6 id=&quot;what-do-they-propose&quot;&gt;What do they propose&lt;/h6&gt;

&lt;p&gt;While StyleGAN uses simple feedforward designs in the
generator (synthesis network) and discriminator, there is a
vast body of work dedicated to the study of better network
architectures. Skip connections [34, 22], residual networks
[18, 17, 31], and hierarchical methods [7, 47, 48] have
proven highly successful also in the context of generative
methods. As such, we decided to re-evaluate the network
design of StyleGAN and search for an architecture that produces high-quality images without progressive growing.
Figure 7a shows MSG-GAN [22], which connects the
matching resolutions of the generator and discriminator using multiple skip connections. The MSG-GAN generator
is modified to output a mipmap [42] instead of an image,
and a similar representation is computed for each real image as well. In Figure 7b we simplify this design by upsampling and summing the contributions of RGB outputs
corresponding to different resolutions. In the discriminator,
we similarly provide the downsampled image to each resolution block of the discriminator. We use bilinear filtering in
all up and downsampling operations. In Figure 7c we further modify the design to use residual connections.3 This
design is similar to LAPGAN [7] without the per-resolution
discriminators employed by Denton et al.&lt;/p&gt;

&lt;h5 id=&quot;method&quot;&gt;Method&lt;/h5&gt;

&lt;p&gt;One of the main strengths of StyleGAN is the ability to
control the generated images via style mixing, i.e., by feeding a different latent w to different layers at inference time.
In practice, style modulation may amplify certain feature
maps by an order of magnitude or more. For style mixing to
work, we must explicitly counteract this amplification on a
per-sample basis — otherwise the subsequent layers would
not be able to operate on the data in a meaningful way.
If we were willing to sacrifice scale-specific controls (see
video), we could simply remove the normalization, thus removing the artifacts and also improving FID slightly [27].
We will now propose a better alternative that removes the
artifacts while retaining full controllability. The main idea
is to base normalization on the expected statistics of the incoming feature maps, but without explicit forcing.&lt;/p&gt;

&lt;h5 id=&quot;result&quot;&gt;Result&lt;/h5&gt;
&lt;p&gt;We have identified and fixed several image quality issues in StyleGAN, improving the quality further and considerably advancing the state of the art in several datasets.
In some cases the improvements are more clearly seen in
motion, as demonstrated in the accompanying video. Appendix A includes further examples of results obtainable using our method. Despite the improved quality, StyleGAN2
makes it easier to attribute a generated image to its source.
Training performance has also improved. At 10242
resolution, the original StyleGAN (config A in Table 1)
trains at 37 images per second on NVIDIA DGX-1 with
8 Tesla V100 GPUs, while our config E trains 40% faster
at 61 img/s. Most of the speedup comes from simplified
dataflow due to weight demodulation, lazy regularization,
and code optimizations. StyleGAN2 (config F, larger networks) trains at 31 img/s, and is thus only slightly more
expensive to train than original StyleGAN. Its total training
time was 9 days for FFHQ and 13 days for LSUN CAR.
The entire project, including all exploration, consumed
132 MWh of electricity, of which 0.68 MWh went into
training the final FFHQ model. In total, we used about
51 single-GPU years of computation (Volta class GPU). A
more detailed discussion is available in Appendix F.
In the future, it could be fruitful to study further improvements to the path length regularization, e.g., by replacing
the pixel-space L2 distance with a data-driven feature-space
metric. Considering the practical deployment of GANs, we
feel that it will be important to find new ways to reduce the
training data requirements. This is especially crucial in applications where it is infeasible to acquire tens of thousands
of training samples, and with datasets that include a lot of
intrinsic variation.&lt;/p&gt;
</description>
                <pubDate>Fri, 06 Dec 2019 00:00:00 +0000</pubDate>
                <link>http://localhost:4000/analyzing-improving-image-quality-stylegan</link>
                <guid isPermaLink="true">http://localhost:4000/analyzing-improving-image-quality-stylegan</guid>
                
                <category>Reiforcement learning</category>
                
                <category>Associative memory</category>
                
                <category>Gradient-Based Meta-Learning</category>
                
                
            </item>
        
            <item>
                <title>DeepFovea: Using deep learning for foveated reconstruction in AR-VR</title>
                <description>&lt;p&gt;&lt;em&gt;Presentation of a Paper avalaible &lt;a href=&quot;https://research.fb.com/wp-content/uploads/2019/11/DeepFovea-Neural-Reconstruction-for-Foveated-Rendering-and-Video-Compression-using-Learned-Statistics-of-Natural-Videos.pdf&quot;&gt;here&lt;/a&gt;&lt;/em&gt;:&lt;/p&gt;

&lt;p&gt;DeepFovea is a new AI-powered 
foveated rendering
 system for augmented and virtual reality displays. It renders images using an order of magnitude fewer pixels than previous systems, producing a full-quality experience that is realistic and 
gaze-contingent
.&lt;/p&gt;

&lt;p&gt;This is the first practical generative adversarial network (GAN) that is able to generate a natural-looking video sequence conditioned on a very sparse input. In our tests, DeepFovea can decrease the amount of compute resources needed for rendering by as much as 10-14x while any image differences remain imperceptible to the human eye.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h5 id=&quot;introduction&quot;&gt;Introduction&lt;/h5&gt;
&lt;p&gt;When the human eye looks directly at an object, it sees it in great detail. Peripheral vision, on the other hand, is much lower quality, but because the brain infers the missing information, humans don’t notice. DeepFovea uses recent advances in 
generative adversarial networks
 (GANs) that can similarly “in-hallucinate” missing peripheral details by generating content that is perceptually consistent. The system is trained by feeding a large number of video sequences with decreased pixel density as input. The input simulates the peripheral image degradation, and the target helps the network learn how to fill in the missing details based on statistics from all the videos it has seen. The result is a natural-looking video generated out of a stream of sparse pixels that has been decreased in density by as much as 99 percent along the periphery of a 60x40 degree field of view. The system also manages the level of flicker, aliasing, and other video artifacts in the periphery to be below the threshold that can be detected by the human eye. (A sample video is available here.)&lt;/p&gt;
&lt;h6 id=&quot;what-do-they-propose&quot;&gt;What do they propose&lt;/h6&gt;

&lt;p&gt;There are several goals that we would like to achieve with our
method. First, the DeepFovea network should be able to operate
in an online mode, i.e., it should be able to reconstruct the current
frame based only on the past frames. Second, since we are targeting
gaze-contingent display systems, the network should be able to
operate in real time. This prohibits using complicated models or any
significant number of past or future frames.
There are also strict requirements for output quality. The human
visual system is not sensitive to high-frequency details in the periphery, however, motion and flicker are easily detectable. Therefore,
while the peripheral reconstruction can omit fine details, it should
not introduce significant noise to achieve plausible results with high
compression. Given the uncertainty of the sparse video input, the
network needs to balance between introducing the new content
timely and suppressing flicker due to the inbound noise.&lt;/p&gt;

&lt;h5 id=&quot;method&quot;&gt;Method&lt;/h5&gt;

&lt;p&gt;For the reconstruction network G of our system (Figure 3), we
chose the U-Net encoder-decoder design with skip connections [Ronneberger et al. 2015]. It transforms an image into a hierarchy and
skip connections allow to bypass high frequencies and improve the
gradient flow during training.
Each decoder block does the reverse of an encoder block, performs
a spatial bilinear upsampling, while decreasing the feature count
correspondingly to the symmetric encoder block. The input to a
decoder block is the upscaled output of the previous decoder block
concatenated with the output of the corresponding encoder block
(skip connection, dashed arrows in Figure 3).
We use ELU activation function [Clevert et al. 2016] in all networks and layers (including recurrent and discriminator layers) to
accelerate the training.&lt;/p&gt;

&lt;h5 id=&quot;result&quot;&gt;Result&lt;/h5&gt;

&lt;p&gt;We presented a neural reconstruction method for foveated rendering and video compression. We show that it is possible to leverage
the spatiotemporal statistics of natural videos to achieve an efficient
video reconstruction in the periphery. Our method demonstrates
temporally stable reconstruction from a noisy input and sets a new
bar of 14x compression rate in savings achievable for foveated rendering with no significant degradation in perceived quality. Because
the method requires only color information as an input, it is also
suitable for foveated compression of video content. We open our
method for follow-up research on foveated reconstruction&lt;/p&gt;
</description>
                <pubDate>Wed, 27 Nov 2019 00:00:00 +0000</pubDate>
                <link>http://localhost:4000/deepfovea-reconstruction-ar-vr</link>
                <guid isPermaLink="true">http://localhost:4000/deepfovea-reconstruction-ar-vr</guid>
                
                <category>Reiforcement learning</category>
                
                <category>Associative memory</category>
                
                <category>Gradient-Based Meta-Learning</category>
                
                
            </item>
        
            <item>
                <title>DeepLine: AutoML Tool for Pipelines Generation using Deep Reinforcement Learning and Hierarchical Actions Filtering</title>
                <description>&lt;p&gt;&lt;em&gt;Presentation of a Paper avalaible &lt;a href=&quot;https://arxiv.org/pdf/1911.00061.pdf&quot;&gt;here&lt;/a&gt;&lt;/em&gt;:&lt;/p&gt;

&lt;p&gt;Automatic machine learning (AutoML) is an area of research
aimed at automating machine learning (ML) activities that
currently require human experts. One of the most challenging tasks in this field is the automatic generation of end-toend ML pipelines: combining multiple types of ML algorithms into a single architecture used for end-to-end analysis of previously-unseen data. This task has two challenging
aspects: the first is the need to explore a large search space
of algorithms and pipeline architectures. The second challenge is the computational cost of training and evaluating
multiple pipelines. In this study we present DeepLine, a reinforcement learning based approach for automatic pipeline
generation. Our proposed approach utilizes an efficient representation of the search space and leverages past knowledge gained from previously-analyzed datasets to make the
problem more tractable. Additionally, we propose a novel
hierarchical-actions algorithm that serves as a plugin, mediating the environment-agent interaction in deep reinforcement learning problems. The plugin significantly speeds up
the training process of our model. Evaluation on 56 datasets
shows that DeepLine outperforms state-of-the-art approaches
both in accuracy and in computational cost&lt;/p&gt;

&lt;!--more--&gt;

&lt;h5 id=&quot;introduction&quot;&gt;Introduction&lt;/h5&gt;
&lt;p&gt;Applying AutoML for end-to-end pipeline generation has
been an active field of research in recent years. Various studies offer a large variety of approaches to address this challenge, including Bayesian optimization (Hutter, Hoos, and
Leyton-Brown 2011) and genetic programming (Olson and
Moore 2016). One popular example is Auto-Weka (Thornton et al. 2013), which automatically selects an algorithm
for each step of a pipeline with a fixed structure and then
uses Bayesian optimization (Sequential model-based optimization) to search for optimal hyperparameter settings of
the pipeline.&lt;/p&gt;
&lt;h6 id=&quot;what-do-they-propose&quot;&gt;What do they propose&lt;/h6&gt;

&lt;p&gt;We implement our agent using the DQN algorithm, which is
an off-policy algorithm. While on-policy algorithms such as
policy gradients are generally more stable, they are also less
sample-efficient and prone to converge to a local optimum.
Moreover, while on-policy approaches generally outperform
off-policy approaches in large action spaces, our hierarchical
representation of actions makes this point irrelevant.
A recent improvement to the DQN algorithm is duelingDQN (D-DQN) (Wang et al. 2015). D-DQN achieves faster
convergence by decoupling the Q-function to the value function of the state and the advantage function of the actions,
thus enabling the DQN agent to learn the value function
V (s), separately from the actions.
The D-DQN architecture consists of two separate subarchitectures – one for the value function and one for the
advantage of each action over the average – each with its
own output layer. Both sub-architectures are fed to a global
output layer which computes the combined loss.
Our implementation is a variation of the D-DQN, which
makes use of the fact that our state representation consists of
multiple components. Our dueling architecture is presented
in Figure 3. We partition the state vector as follows: the vectors that model the state of the grid form the input to the
value-function sub-architecture.&lt;/p&gt;

&lt;h5 id=&quot;method&quot;&gt;Method&lt;/h5&gt;

&lt;p&gt;We first perform full ablations of the gating variants (Section 4.1) on two common benchmarks for testing memory
models: synthetic memory tasks and pixel-by-pixel image
classification tasks. We then evaluate our main method
on important applications for recurrent models including
language modeling and reinforcement learning, comparing
against baselines from literature where appropriate.
The main claims we evaluate for each gating component
are (i) the refine gate is more effective than alternatives
(the master gate, or no auxiliary gate), and (ii) UGI is more
effective than standard initialization for sigmoid gates. In
particular, we expect the &lt;em&gt;R gate to be more effective than
*M or *- for any primary gate *, and we expect U&lt;/em&gt; to be
better than -* and comparable to O* for any auxiliary gate *.&lt;/p&gt;

&lt;h5 id=&quot;result&quot;&gt;Result&lt;/h5&gt;
&lt;p&gt;Open-ended learning systems that utilise learning-based agents and self-play have achieved impressive results in increasingly challenging domains. Thanks to advances in imitation learning, reinforcement learning, and the League, we were able to train AlphaStar Final, an agent that reached Grandmaster level at the full game of StarCraft II without any modifications, as shown in the above video. This agent played online anonymously, using the gaming platform Battle.net, and achieved a Grandmaster level using all three StarCraft II races. AlphaStar played using a camera interface, with similar information to what human players would have, and with restrictions on its action rate to make it comparable with human players. The interface and restrictions were approved by a professional player. Ultimately, these results provide strong evidence that general-purpose learning techniques can scale AI systems to work in complex, dynamic environments involving multiple actors. The techniques we used to develop AlphaStar will help further the safety and robustness of AI systems in general, and, we hope, may serve to advance our research in real-world domains.&lt;/p&gt;
</description>
                <pubDate>Wed, 13 Nov 2019 00:00:00 +0000</pubDate>
                <link>http://localhost:4000/deepline-automl-pipelines-generation</link>
                <guid isPermaLink="true">http://localhost:4000/deepline-automl-pipelines-generation</guid>
                
                <category>DeepLine</category>
                
                <category>Associative memory</category>
                
                <category>Gradient-Based Meta-Learning</category>
                
                
            </item>
        
            <item>
                <title>AlphaStar: Grandmaster level in StarCraft II using multi-agent reinforcement learning</title>
                <description>&lt;p&gt;&lt;em&gt;Presentation of a Paper avalaible &lt;a href=&quot;https://www.nature.com/articles/s41586-019-1724-z.epdf?author_access_token=lZH3nqPYtWJXfDA10W0CNNRgN0jAjWel9jnR3ZoTv0PSZcPzJFGNAZhOlk4deBCKzKm70KfinloafEF1bCCXL6IIHHgKaDkaTkBcTEv7aT-wqDoG1VeO9-wO3GEoAMF9bAOt7mJ0RWQnRVMbyfgH9A%3D%3D&quot;&gt;here&lt;/a&gt;&lt;/em&gt;:&lt;/p&gt;

&lt;p&gt;Many real-world applications require artificial agents to compete and coordinate with other agents in complex environments. As a stepping stone to this goal, the domain of StarCraft has emerged as an important challenge for artificial intelligence research, owing to its iconic and enduring status among the most difficult professional esports and its relevance to the real world in terms of its raw complexity and multi-agent challenges. Over the course of a decade and numerous competitions1,2,3, the strongest agents have simplified important aspects of the game, utilized superhuman capabilities, or employed hand-crafted sub-systems4. Despite these advantages, no previous agent has come close to matching the overall skill of top StarCraft players. We chose to address the challenge of StarCraft using general-purpose learning methods that are in principle applicable to other complex domains: a multi-agent reinforcement learning algorithm that uses data from both human and agent games within a diverse league of continually adapting strategies and counter-strategies, each represented by deep neural networks5,6. We evaluated our agent, AlphaStar, in the full game of StarCraft II, through a series of online games against human players. AlphaStar was rated at Grandmaster level for all three StarCraft races and above 99.8% of officially ranked human players.
&lt;!--more--&gt;&lt;/p&gt;

&lt;h5 id=&quot;introduction&quot;&gt;Introduction&lt;/h5&gt;
&lt;p&gt;We chose to use general-purpose machine learning techniques – including neural networks, self-play via reinforcement learning, multi-agent learning, and imitation learning – to learn directly from game data with general purpose techniques. Using the advances described in our Nature paper, AlphaStar was ranked above 99.8% of active players on Battle.net, and achieved a Grandmaster level for all three StarCraft II races: Protoss, Terran, and Zerg. We expect these methods could be applied to many other domains.&lt;/p&gt;
&lt;h6 id=&quot;what-do-they-propose&quot;&gt;What do they propose&lt;/h6&gt;

&lt;p&gt;Learning-based systems and self-play are elegant research concepts which have facilitated remarkable advances in artificial intelligence. In 1992, researchers at IBM developed TD-Gammon, combining a learning-based system with a neural network to play the game of backgammon. Instead of playing according to hard-coded rules or heuristics, TD-Gammon was designed to use reinforcement learning to figure out, through trial-and-error, how to play the game in a way that maximises its probability of winning. Its developers used the notion of self-play to make the system more robust: by playing against versions of itself, the system grew increasingly proficient at the game. When combined, the notions of learning-based systems and self-play provide a powerful paradigm of open-ended learning.&lt;/p&gt;

&lt;h5 id=&quot;method&quot;&gt;Method&lt;/h5&gt;

&lt;p&gt;We first perform full ablations of the gating variants (Section 4.1) on two common benchmarks for testing memory
models: synthetic memory tasks and pixel-by-pixel image
classification tasks. We then evaluate our main method
on important applications for recurrent models including
language modeling and reinforcement learning, comparing
against baselines from literature where appropriate.
The main claims we evaluate for each gating component
are (i) the refine gate is more effective than alternatives
(the master gate, or no auxiliary gate), and (ii) UGI is more
effective than standard initialization for sigmoid gates. In
particular, we expect the &lt;em&gt;R gate to be more effective than
*M or *- for any primary gate *, and we expect U&lt;/em&gt; to be
better than -* and comparable to O* for any auxiliary gate *.&lt;/p&gt;

&lt;h5 id=&quot;result&quot;&gt;Result&lt;/h5&gt;
&lt;p&gt;Open-ended learning systems that utilise learning-based agents and self-play have achieved impressive results in increasingly challenging domains. Thanks to advances in imitation learning, reinforcement learning, and the League, we were able to train AlphaStar Final, an agent that reached Grandmaster level at the full game of StarCraft II without any modifications, as shown in the above video. This agent played online anonymously, using the gaming platform Battle.net, and achieved a Grandmaster level using all three StarCraft II races. AlphaStar played using a camera interface, with similar information to what human players would have, and with restrictions on its action rate to make it comparable with human players. The interface and restrictions were approved by a professional player. Ultimately, these results provide strong evidence that general-purpose learning techniques can scale AI systems to work in complex, dynamic environments involving multiple actors. The techniques we used to develop AlphaStar will help further the safety and robustness of AI systems in general, and, we hope, may serve to advance our research in real-world domains.&lt;/p&gt;
</description>
                <pubDate>Mon, 04 Nov 2019 00:00:00 +0000</pubDate>
                <link>http://localhost:4000/alphastar-agent-reinforcement-learning</link>
                <guid isPermaLink="true">http://localhost:4000/alphastar-agent-reinforcement-learning</guid>
                
                <category>Reiforcement learning</category>
                
                <category>Imitation learning</category>
                
                <category>AlphaStar</category>
                
                <category>Multi Agent System</category>
                
                
            </item>
        
            <item>
                <title>Improving the Gating Mechanism of Recurrent Neural Networks</title>
                <description>&lt;p&gt;&lt;em&gt;Presentation of a Paper avalaible &lt;a href=&quot;https://arxiv.org/pdf/1910.09890.pdf&quot;&gt;here&lt;/a&gt;&lt;/em&gt;:&lt;/p&gt;

&lt;p&gt;Gating mechanisms are widely used in neural
network models, where they allow gradients to
backpropagate more easily through depth or time.
However, their saturation property introduces
problems of its own. For example, in recurrent
models these gates need to have outputs near 1
to propagate information over long time-delays,
which requires them to operate in their saturation
regime and hinders gradient-based learning of
the gate mechanism. We address this problem by
deriving two synergistic modifications to the standard gating mechanism that are easy to implement,
introduce no additional hyperparameters, and
improve learnability of the gates when they are
close to saturation. We show how these changes
are related to and improve on alternative recently
proposed gating mechanisms such as chrono
initialization and Ordered Neurons. Empirically,
our simple gating mechanisms robustly improve
the performance of recurrent models on a range
of applications, including synthetic memorization
tasks, sequential image classification, language
modeling, and reinforcement learning, particularly
when long-term dependencies are involved.
&lt;!--more--&gt;&lt;/p&gt;

&lt;h5 id=&quot;introduction&quot;&gt;Introduction&lt;/h5&gt;
&lt;p&gt;Recurrent neural networks (RNNs) are an established
machine learning tool for learning from sequential data.
However, RNNs are prone to the vanishing gradient problem,
which occurs when the gradients of the recurrent weights become vanishingly small as they get backpropagated through
time (Hochreiter, 1991; Bengio et al., 1994; Hochreiter
et al., 2001). A common approach to alleviate the vanishing
gradient problem is to use gating mechanisms, leading to
models such as the long short term memory (Hochreiter
&amp;amp; Schmidhuber, 1997, LSTM) and gated recurrent units
1
Stanford University, USA 2DeepMind, London, UK. Correspondence to: Albert Gu &lt;a href=&quot;mailto:albertgu@stanford.edu&quot;&gt;albertgu@stanford.edu&lt;/a&gt;, Caglar Gulcehre &lt;a href=&quot;mailto:caglarg@google.com&quot;&gt;caglarg@google.com&lt;/a&gt;.
Proceedings of the 37 th International Conference on Machine
Learning, Vienna, Austria, PMLR 108, 2020. Copyright 2020 by
the author(s).
(Chung et al., 2014, GRUs). These gated RNNs have been
very successful in several different application areas such
as in reinforcement learning (Kapturowski et al., 2018;
Espeholt et al., 2018) and natural language processing
(Bahdanau et al., 2014; Kocisk ˇ y et al. ` , 2018).&lt;/p&gt;
&lt;h6 id=&quot;what-do-they-propose&quot;&gt;What do they propose&lt;/h6&gt;

&lt;p&gt;The URLSTM requires two small modifications to the
vanilla LSTM. First, we present the way the biases of forget
gates are initialized in Equation (12) with UGI. Second,
the modifications on the standard LSTM equations to
compute the refine and effective forget gates are presented
in Equations (9)-(11). However, we note that these methods
can be used to modify any gate (or more generally, bounded
function) in any model. In this context, the URLSTM is
simply defined by applying UGI and a refine gate r on the
original forget gate f to create an effective forget gate g
(Equation (10)). This effective gate is then used in the cell
state update (11). Empirically, these small modifications
to an LSTM are enough to allow it to achieve nearly binary
activations and solve difficult memory problems (Figure 5).&lt;/p&gt;

&lt;h5 id=&quot;method&quot;&gt;Method&lt;/h5&gt;

&lt;p&gt;We first perform full ablations of the gating variants (Section 4.1) on two common benchmarks for testing memory
models: synthetic memory tasks and pixel-by-pixel image
classification tasks. We then evaluate our main method
on important applications for recurrent models including
language modeling and reinforcement learning, comparing
against baselines from literature where appropriate.
The main claims we evaluate for each gating component
are (i) the refine gate is more effective than alternatives
(the master gate, or no auxiliary gate), and (ii) UGI is more
effective than standard initialization for sigmoid gates. In
particular, we expect the &lt;em&gt;R gate to be more effective than
*M or *- for any primary gate *, and we expect U&lt;/em&gt; to be
better than -* and comparable to O* for any auxiliary gate *.&lt;/p&gt;

&lt;h5 id=&quot;result&quot;&gt;Result&lt;/h5&gt;
&lt;p&gt;In this work, we introduce and evaluate several modifications
to the ubiquitous gating mechanism that appears in recurrent
neural networks. We describe methods that improve
on the standard gating method by alleviating problems
with initialization and optimization. The mechanisms
considered include changes on independent axes, namely
initialization/activations and auxiliary gates, and we perform
extensive ablations on our improvements with previously
considered modifications. Our main gate model robustly
improves on standard gates across many different tasks and
recurrent cores, while requiring less tuning. Finally, we
emphasize that these improvements are entirely independent
of the large body of research on neural network architectures
that use gates, and hope that these insights can be applied
to improve machine learning models at large.&lt;/p&gt;
</description>
                <pubDate>Wed, 30 Oct 2019 00:00:00 +0000</pubDate>
                <link>http://localhost:4000/improving-gating-mechanism-recurrent-neural-networks</link>
                <guid isPermaLink="true">http://localhost:4000/improving-gating-mechanism-recurrent-neural-networks</guid>
                
                <category>Recurrent Neural Networks</category>
                
                <category>Associative memory</category>
                
                <category>Gradient-Based Meta-Learning</category>
                
                <category>Backpropagation</category>
                
                
            </item>
        
            <item>
                <title>Meta-Learning Deep Energy-Based Memory Models</title>
                <description>&lt;p&gt;&lt;img src=&quot;https://ars.els-cdn.com/content/image/1-s2.0-S1568494619306350-gr3.jpg&quot; alt=&quot;drawing&quot; width=&quot;auto&quot; max-width=&quot;100%&quot; height=&quot;50%&quot; /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Presentation of a Paper avalaible &lt;a href=&quot;https://arxiv.org/pdf/1910.02720.pdf&quot;&gt;here&lt;/a&gt;&lt;/em&gt;:&lt;/p&gt;

&lt;p&gt;We study the problem of learning associative memory – a system which is able to retrieve a remembered pattern based on its distorted or incomplete version. Attractor networks provide a sound model of associative memory: patterns are stored as attractors of the network dynamics and associative retrieval is performed by running the dynamics starting from a query pattern until it converges to an attractor. In such models the dynamics are often implemented as an optimization procedure that minimizes an energy function, such as in the classical Hopfield network. In general it is difficult to derive a writing rule for a given dynamics and energy that is both compressive and fast. Thus, most research in energybased memory has been limited either to tractable energy models not expressive enough to handle complex high-dimensional objects such as natural images, or to models that do not offer fast writing. We present a novel meta-learning approach to energy-based memory models (EBMM) that allows one to use an arbitrary neural architecture as an energy model and quickly store patterns in its weights. We demonstrate experimentally that our EBMM approach can build compressed memories for synthetic and natural data, and is capable of associative retrieval that outperforms existing memory systems in terms of the reconstruction error and compression rate.
&lt;!--more--&gt;&lt;/p&gt;

&lt;h5 id=&quot;introduction&quot;&gt;Introduction&lt;/h5&gt;

&lt;p&gt;Associative memory has long been of interest to neuroscience and machine learning communities (Willshaw et al., 1969; Hopfield, 1982; Kanerva, 1988). This interest has generated many proposals for associative memory models, both biological and synthetic. These models address the problem of storing a set of patterns in such a way that a stored pattern can be retrieved based on a partially known or distorted version. This kind of retrieval from memory is known as auto-association.&lt;/p&gt;

&lt;h6 id=&quot;what-do-they-propose&quot;&gt;What do they propose&lt;/h6&gt;

&lt;p&gt;In this section we experimentally evaluate EBMM on a number of real-world image datasets.
The performance of EBMM is compared to a set of relevant baselines: Long-Short Term Memory (LSTM) (Hochreiter &amp;amp; Schmidhuber, 1997), the classical Hopfield network (Hopfield, 1982), Memory-Augmented Neural Networks (MANN) (Santoro et al., 2016) (which are a variant of the Differentiable Neural Computer (Graves et al., 2016)), Memory Networks (Weston et al., 2014), Differentiable Plasticity model of Miconi et al. (2018) (a generalization of the Fast-weights RNN (Ba et al., 2016)) and Dynamic Kanerva Machine (Wu et al., 2018). Some of these baselines failed to learn at all for real-world images. In the Appendix A.2 we provide additional experiments with random binary strings with a larger set of representative models. The experimental procedure is the following: we write a fixed-sized batch of images into a memory model, then corrupt a random block of the written image to form a query and let the model retrieve the originally stored image. By varying the memory size and repeating this procedure, we perform distortion/rate analysis, i.e. we measure how well a memory model can retrieve a remembered pattern for a given memory size.&lt;/p&gt;

&lt;h5 id=&quot;method&quot;&gt;Method&lt;/h5&gt;

&lt;p&gt;Deep neural networks are capable of both compression (Parkhi et al., 2015; Kraska et al., 2018),
and memorizing training patterns (Zhang et al., 2016). Taken together, these properties make
deep networks an attractive candidate for memory models, with both exact recall and compressive
capabilities. However, there exists a natural trade-off between the speed of writing and the realizable
capacity of a model (Ba et al., 2016). Approaches similar to ours in their use of gradient descent
dynamics, but lacking fast writing, have been proposed by Hinton et al. (2006a) and recently revisited
by Du &amp;amp; Mordatch (2019) together with another stochastic deep energy model (Krotov &amp;amp; Hopfield,
2016). In general it is difficult to derive a writing rule for a given dynamics equation or an energy
model which we attempt to address in this work.
We introduced a novel learning method for deep associative memory systems. Our method benefits
from the recent progress in deep learning so that we can use a very large class of neural networks both
8
Preprint
for learning representations and for storing patterns in network weights. At the same time, we are not
bound by slow gradient learning thanks to meta-learning of fast writing rules. We showed that our
method is applicable in a variety of domains from non-compressible (binary strings; see Appendix)
to highly compressible (natural images) and that the resulting memory system uses available capacity
efficiently. We believe that more elaborate architecture search could lead to stronger results on par
with state-of-the-art generative models.
The existing limitation of EBMM is the batch writing assumption, which is in principle possible to
relax. This would enable embedding of the model in reinforcement learning agents or into other tasks
requiring online-updating memory. It would be also interesting to explore a stochastic variant of
EBMM that could return different associations in the presence of uncertainty caused by compression.
Finally, many general principles of learning attractor models with desired properties are yet to be
discovered and we believe that our results provide a good motivation for this line of research.&lt;/p&gt;
</description>
                <pubDate>Mon, 21 Oct 2019 00:00:00 +0100</pubDate>
                <link>http://localhost:4000/meta-learning-deep-energy-based-memory-models</link>
                <guid isPermaLink="true">http://localhost:4000/meta-learning-deep-energy-based-memory-models</guid>
                
                <category>Energy-based Memory Models</category>
                
                <category>Associative memory</category>
                
                <category>Gradient-Based Meta-Learning</category>
                
                <category>EBMM</category>
                
                
            </item>
        
            <item>
                <title>Stacked Autoencoder Based Deep Random Vector Functional Link Neural Network for Classification</title>
                <description>&lt;p&gt;&lt;img src=&quot;https://ars.els-cdn.com/content/image/1-s2.0-S1568494619306350-gr3.jpg&quot; alt=&quot;drawing&quot; width=&quot;auto&quot; max-width=&quot;100%&quot; height=&quot;50%&quot; /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Presentation of a Paper avalaible : &lt;a href=&quot;https://arxiv.org/pdf/1910.01858.pdf&quot;&gt;here&lt;/a&gt;&lt;/em&gt;\&lt;/p&gt;

&lt;p&gt;Extreme learning machine (ELM), which can be viewed as a variant of Random Vector Functional Link (RVFL) network without the input-output direct connections, has been extensively used to create multi-layer (deep) neural networks.
Such networks employ randomization based autoencoders (AE) for unsupervised feature extraction followed by an ELM classifier for final decision making. Each randomization based AE acts as an independent feature extractor and a deep network is obtained by stacking several such AEs. Inspired by the better performance of RVFL over ELM, in this paper, we propose several deep RVFL variants by utilizing the framework of stacked autoencoders. Specifically, we introduce direct connections (feature reuse) from preceding layers to the fore layers of the network as in the original RVFL network. Such connections help to regularize the randomization and also reduce the model complexity. Furthermore, we also introduce denoising criterion, recovering clean inputs from their corrupted versions, in the autoencoders to achieve better higher level representations than the ordinary autoencoders. Extensive experiments on several classification datasets show that our proposed deep networks achieve overall better and faster generalization than the other relevant state-of-the-art deep neural networks.
&lt;!--more--&gt;&lt;/p&gt;

&lt;h5 id=&quot;introduction&quot;&gt;Introduction&lt;/h5&gt;
&lt;p&gt;Deep or multi-layer neural network has become a popular machine learning
method in recent years. From image classification to action recognition to many other tasks, deep neural networks (DNNs) are ubiquitously used [1]. The power
of deep learning, also known as representational learning, stems from its meaningful feature extraction capabilities via multiple hidden layers [2]. Deep neural
networks are successful because they can extract complex structures and build
an internal representation from several hidden layers [3]. One among many
techniques of creating a deep neural network is based on an autoencoder (AE).
Multiple AEs are stacked together to create a deep neural network. The AE
performs meaningful feature extraction and thus, used as a building block to
create a deep neural network [4].&lt;/p&gt;

&lt;h6 id=&quot;what-do-they-propose&quot;&gt;What do they propose&lt;/h6&gt;

&lt;p&gt;In this section, we discuss the fundamentals of RVFL, ELM as a variant
of RVFL, Kernel ELM, autoencoder (AE) and denoising autoencoder (DAE).
To facilitate the understanding of how AEs (or DAEs) are used to build multilayer neural networks, we briefly review the concepts of Stacked AE (SAE) and
Stacked DAE (SDA). We also present a detailed review of ELM based multilayer neural networks.&lt;/p&gt;

&lt;h5 id=&quot;method&quot;&gt;Method&lt;/h5&gt;

&lt;p&gt;They dataset is composed with images and textual description in the form of natural language or a set of key words.
During the training, they transform images into unit vector by defining the mini-batch weakly&lt;/p&gt;
</description>
                <pubDate>Tue, 15 Oct 2019 00:00:00 +0100</pubDate>
                <link>http://localhost:4000/stacked-autoencoder-deep-random-vector</link>
                <guid isPermaLink="true">http://localhost:4000/stacked-autoencoder-deep-random-vector</guid>
                
                <category>Stacked Autoencoder</category>
                
                <category>Random Vector Functional Link</category>
                
                <category>Extreme Learning Machine</category>
                
                <category>Deep Learning</category>
                
                
            </item>
        
            <item>
                <title>Celeb-DF: A New Dataset for DeepFake Forensics</title>
                <description>&lt;p&gt;&lt;img src=&quot;https://i.kinja-img.com/gawker-media/image/upload/c_scale,fl_progressive,q_80,w_800/rdvjaoctz3zp9cv9nbim.jpg&quot; alt=&quot;drawing&quot; width=&quot;auto&quot; max-width=&quot;100%&quot; height=&quot;50%&quot; /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Presentation of a Paper avalaible : &lt;a href=&quot;https://arxiv.org/pdf/1909.12962.pdf&quot;&gt;here&lt;/a&gt;&lt;/em&gt;\&lt;/p&gt;

&lt;p&gt;AI-synthesized face-swapping videos, commonly known as DeepFakes, is an emerging problem threatening the trustworthiness of online information. The need to develop and evaluate DeepFake detection algorithms calls for large-scale datasets. However, current DeepFake datasets
suffer from low visual quality and do not resemble DeepFake videos circulated on the Internet. We present a new large-scale challenging DeepFake video dataset, CelebDF, which contains 5, 639 high-quality DeepFake videos of celebrities generated using improved synthesis process. We
conduct a comprehensive evaluation of DeepFake detection methods and datasets to demonstrate the escalated level of challenges posed by Celeb-DF.
&lt;!--more--&gt;&lt;/p&gt;

&lt;h5 id=&quot;introduction&quot;&gt;Introduction&lt;/h5&gt;
&lt;p&gt;In this work, we present a new large-scale and challenging DeepFake video dataset, Celeb-DF3
, for the development and evaluation of DeepFake detection algorithms.
There are in total 5, 639 DeepFake videos, corresponding more than 2 million frames, in the Celeb-DF dataset.
The real source videos are based on publicly available
YouTube video clips of 59 celebrities of diverse genders,
ages, and ethic groups. The DeepFake videos are generated
using an improved DeepFake synthesis method. As a result, the overall visual quality of the synthesized DeepFake
videos in Celeb-DF is greatly improved when compared to
existing datasets, with significantly fewer notable visual artifacts, see Fig.2. Based on the Celeb-DF dataset and other
existing datasets, we conduct an evaluation of current DeepFake detection methods.&lt;/p&gt;

&lt;h6 id=&quot;what-do-they-propose&quot;&gt;What do they propose&lt;/h6&gt;

&lt;p&gt;The DeepFake videos in Celeb-DF are generated using an improved DeepFake synthesis algorithm, which is key to the improved visual quality as shown in Fig.2. Specifically, the basic DeepFake maker algorithm is refined in several aspects targeting the following specific visual artifacts observed in existing datasets.&lt;/p&gt;

&lt;h5 id=&quot;method&quot;&gt;Method&lt;/h5&gt;

&lt;p&gt;They dataset is composed with images and textual description in the form of natural language or a set of key words.
During the training, they transform images into unit vector by defining the mini-batch weakly&lt;/p&gt;

</description>
                <pubDate>Wed, 09 Oct 2019 00:00:00 +0100</pubDate>
                <link>http://localhost:4000/celeb-ed-dataset-deepfake</link>
                <guid isPermaLink="true">http://localhost:4000/celeb-ed-dataset-deepfake</guid>
                
                <category>Celeb-DF</category>
                
                <category>Computer Vision</category>
                
                <category>DeepFake</category>
                
                <category>Algorithms</category>
                
                
            </item>
        
            <item>
                <title>Gated Linear Networks</title>
                <description>&lt;p&gt;&lt;img src=&quot;https://yt3.ggpht.com/a/AGF-l7-ncmSiLyMlXHexWBJfa61xH8Y02WWQbnI4rg=s900-c-k-c0xffffffff-no-rj-mo&quot; alt=&quot;drawing&quot; width=&quot;auto&quot; max-width=&quot;100%&quot; height=&quot;50%&quot; /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Presentation of a Paper avalaible : &lt;a href=&quot;https://arxiv.org/pdf/1910.01526.pdf&quot;&gt;here&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;This paper presents a family of backpropagation-free neural architectures, Gated Linear Networks (GLNs), that are well suited to online learning applications where sample efficiency is of paramount importance. The impressive empirical performance of these architectures has long been known within the data compression community, but a theoretically satisfying explanation as to how and why they perform so well has proven difficult.
It’s written by Joel Veness, Tor Lattimore, Avishkar Bhoopchand, David Budden, Christopher Mattern, Agnieszka Grabska-Barwinska, Peter Toth, Simon Schmitt and Marcus Hutter from DeepMind.
&lt;!--more--&gt;&lt;/p&gt;

&lt;h5 id=&quot;introduction&quot;&gt;Introduction&lt;/h5&gt;
&lt;p&gt;What distinguishes these architectures from other neural systems is the distributed and local nature of their credit assignment mechanism; each neuron directly predicts the target and has its own set of hard-gated weights that are locally adapted via online convex optimization. By providing an interpretation, generalization and subsequent theoretical analysis, we show that sufficiently large GLNs
are universal in a strong sense: not only can they model any compactly supported, continuous density function to arbitrary accuracy, but that any choice of no-regret online convex optimization technique will provably converge to the correct solution with enough data. Empirically we show a collection of single-pass learning results on established machine learning benchmarks that are competitive with results obtained with general purpose batch learning techniques.&lt;/p&gt;

&lt;h6 id=&quot;what-do-they-propose-&quot;&gt;What do they propose ?&lt;/h6&gt;

&lt;p&gt;Deep metric learning algorithms fail to learn distances that capture fined-grained sub-categories. Such fine-grained visual similarity distances are important to learn generalized visual features and to have robust performance on cross-domain data. So they construct an embedding of the product with text product production and use this to drive an adaptive triplet loss.&lt;/p&gt;

&lt;h5 id=&quot;method&quot;&gt;Method&lt;/h5&gt;

&lt;p&gt;They dataset is composed with images and textual description in the form of natural language or a set of key words.
During the training, they transform images into unit vector by defining the mini-batch weakly&lt;/p&gt;

&lt;h5 id=&quot;discussion&quot;&gt;Discussion&lt;/h5&gt;

&lt;p&gt;We have introduced a new family of general purpose neural architectures, Gated Linear Networks, and studied the
desirable characteristics that follow from their use of datadependent gating and local credit assignment. Their fast
online learning properties, easy interpretability, and excellent robustness to catastrophic forgetting in continual learning settings makes them an interesting and complementary
alternative to contemporary deep learning approaches.&lt;/p&gt;
</description>
                <pubDate>Mon, 07 Oct 2019 00:00:00 +0100</pubDate>
                <link>http://localhost:4000/gated-linear-networks</link>
                <guid isPermaLink="true">http://localhost:4000/gated-linear-networks</guid>
                
                <category>Backpropagation</category>
                
                <category>Gated Linear Networks</category>
                
                <category>Probabilistic Models</category>
                
                <category>Gated Geometric Mixture</category>
                
                
            </item>
        
            <item>
                <title>BERT ?</title>
                <description>&lt;p&gt;&lt;img src=&quot;https://github.com/mbenhamd/artificialmind-website/blob/master/images/Bert_smile.png?raw=true&quot; alt=&quot;drawing&quot; width=&quot;auto&quot; max-width=&quot;100%&quot; height=&quot;100%&quot; /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Explanation of the model which upset the natural processing of language: &lt;a href=&quot;https://arxiv.org/pdf/1810.04805.pdf&quot;&gt;Publication&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;According to the researchers who designed BERT (Bidirectional Encoder Representations from Transformers) was thought to pre-form deep two-way representations from unlabeled text and jointly conditioning the left and right contexts. The result gives us that a pre-trained model can be refined by adding an additional superficial layer to meet the NLP task.&lt;/p&gt;

&lt;!--more--&gt;

&lt;!---
Write an intro (and make it captivating).
--&gt;

&lt;h5 id=&quot;who-is-bert-&quot;&gt;Who is BERT ?&lt;/h5&gt;

&lt;p&gt;No, it is not the first name as you could have understood it thanks to the title and the small introduction but beautiful and well a framework which can help you to solve your NLP projects. Coming from the Language department at Google Research and it has inspired many architectures known for example the OpenAI GPT-2 model.&lt;/p&gt;

&lt;h5 id=&quot;why-did-we-come-up-with-this&quot;&gt;Why did we come up with this?&lt;/h5&gt;

&lt;p&gt;We had some problems with previous methods because language models only use left context or right context, but language understanding is bidirectional. 
There are two main reasons why language models are unidirectional : 
Directionality is necessitated to make a well-formed probability pattern. The second idea is that information can be seen in a bidirectional encoder.&lt;/p&gt;

&lt;h5 id=&quot;bert-explained&quot;&gt;BERT Explained&lt;/h5&gt;

&lt;p&gt;There are useful articles on that subject that you should read. I would advice two of them that cover fundamentals and other questions. 
&lt;a href=&quot;https://jalammar.github.io/illustrated-bert/&quot;&gt;The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)&lt;/a&gt;
&lt;a href=&quot;https://yashuseth.blog/2019/06/12/bert-explained-faqs-understand-bert-working/#:~:text=What%20is%20BERT%3F,task%2Dspecific%20fine%2Dtuning.&quot;&gt;BERT Explained – A list of Frequently Asked Questions&lt;/a&gt;&lt;/p&gt;

</description>
                <pubDate>Sat, 05 Oct 2019 00:00:00 +0100</pubDate>
                <link>http://localhost:4000/Bidirectional-Encoder-Representations-from-Transformers</link>
                <guid isPermaLink="true">http://localhost:4000/Bidirectional-Encoder-Representations-from-Transformers</guid>
                
                <category>BERT</category>
                
                <category>NLP</category>
                
                <category>state-of-the-art</category>
                
                <category>Tranformers</category>
                
                
            </item>
        
            <item>
                <title>A weakly supervised adaptive triplet loss for deep metric learning</title>
                <description>&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1204/0*_WNBFcRVEOz6QM7R.&quot; alt=&quot;drawing&quot; width=&quot;auto&quot; max-width=&quot;100%&quot; height=&quot;100%&quot; /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Presentation of a Paper avalaible &lt;a href=&quot;https://arxiv.org/pdf/1909.12939.pdf&quot;&gt;here&lt;/a&gt;&lt;/em&gt;:&lt;/p&gt;

&lt;p&gt;The article presents an approach to the major problems of learning metrics on the search for similarities in the case of image data sets. The authors present a method called a weakly supervised adaptrive triplet loss (ATL) that can capture fine-grained semantic similarity.
It’s written by Xiaonan Zthao, Hian Qi, Rui Luo and Larry Davis from Amazon R&amp;amp;D.
&lt;!--more--&gt;&lt;/p&gt;

&lt;h5 id=&quot;introduction&quot;&gt;Introduction&lt;/h5&gt;
&lt;p&gt;In this paper, they apply different distance metric learning on fashion datasets. We can cite a well-known named DeepFashion that contains over 800,000 diverse fashion images ranging from well-posed shop images to unconstrained consumer photos and it is annotated with rich information of clothing items. Each image in this dataset is labeled with 50 categories, 1,000 descriptive attributes, bounding box and clothing landmarks.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion/attributes.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A lot of approaches exist like contrastive loss where it produce a high loss (a penalty) when predicted distance is large when two object are similar and a low loss when the predicted distance is small, and vice versa for the case when the objects are different. Then we have triplet loss where a baseline (anchor) input is compared to a positive (truthy) input and a negative (falsy) input. The distance from the baseline (anchor) input to the positive (truthy) input is minimized, and the distance from the baseline (anchor) input to the negative (falsy) input is maximized. In other word, in triplet loss training a triplet contains two images belonging to the same class, referred to as the anchor and positive samples, and a thirs image, from a different class, which is referred to as the negative sample.&lt;/p&gt;

\[d(a,p)-d(a,n)+m\]

&lt;p&gt;where a,p and n are anchor, positive and negative samples, respectively \(d(.,.)\) is the learned metric function and \(m\) is a margin term which encourages the negative sample to be further from the nachor than the positive sample. As they write in their paper, DNN base trimplet loss training commonly uses stochastic gradient decent on mini batches.&lt;/p&gt;

&lt;h6 id=&quot;what-do-they-propose&quot;&gt;What do they propose&lt;/h6&gt;

&lt;p&gt;Deep metric learning algorithms fail to learn distances that capture fined-grained sub-categories. Such fine-grained visual similarity distances are important to learn generalized visual features and to have robust performance on cross-domain data. So they construct an embedding of the product with text product production and use this to drive an adaptive triplet loss.&lt;/p&gt;

&lt;h5 id=&quot;method&quot;&gt;Method&lt;/h5&gt;

&lt;p&gt;They dataset is composed with images and textual description in the form of natural language or a set of key words.
During the training, they transform images into unit vector by defining the mini-batch weakly&lt;/p&gt;

&lt;h5 id=&quot;result&quot;&gt;Result&lt;/h5&gt;

&lt;h5 id=&quot;discussion&quot;&gt;Discussion&lt;/h5&gt;
</description>
                <pubDate>Tue, 01 Oct 2019 00:00:00 +0100</pubDate>
                <link>http://localhost:4000/weakly-supervised-adaptive-triplet-loss</link>
                <guid isPermaLink="true">http://localhost:4000/weakly-supervised-adaptive-triplet-loss</guid>
                
                <category>Loss</category>
                
                <category>Weakly Supervised</category>
                
                <category>Learning Metrics</category>
                
                <category>Triplet Loss</category>
                
                <category>Semantic Classes</category>
                
                
            </item>
        
            <item>
                <title>Twitter Sentiment Analysis</title>
                <description>&lt;p&gt;&lt;img src=&quot;https://github.com/mbenhamd/database-publication-latex/blob/master/real_stream-schema.png?raw=true&quot; alt=&quot;drawing&quot; width=&quot;auto&quot; max-width=&quot;100%&quot; height=&quot;100%&quot; /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Presentation of a Twitter Sentiment Analysis available on my &lt;a href=&quot;https://github.com/mbenhamd/twitter-sentiment-analysis&quot;&gt;Github repository&lt;/a&gt; and &lt;a href=&quot;https://github.com/mbenhamd/database-publication-latex/blob/master/publication.pdf&quot;&gt;Publication&lt;/a&gt;&lt;/em&gt;:&lt;/p&gt;

&lt;h3 id=&quot;technologies&quot;&gt;Technologies&lt;/h3&gt;

&lt;p&gt;Scikit-learn, Spark, AWS EMR, S3, Lambda, Kinesis, API Gateway, MQTT, React JS, RDS (Postgres SQL).&lt;/p&gt;

&lt;!--more--&gt;

&lt;h5 id=&quot;define-a-problem-you-want-to-solve&quot;&gt;Define a problem you want to solve&lt;/h5&gt;

&lt;p&gt;Our main purpose is to build a powerful platform system for real-time data analysis of tweets on twitter trends. We also want to analyse all the tweets of 2017 based on a downloaded sample of data (average of 6 To). All this data analysis will be accessible via a web interface that will be developed. We want to build a powerful system of sentiments analysis by making a database structure of tweets which is relevant about impacts and effects. The system should provide a faster way to execute Machine Learning methodologies behind data extracted from Twitter. Analysis news actuality by getting an analysis on actual trends with real stream data and building an efficient web interface to get results easily and keep a control on data continuously. We also wanted to make a comparison of sentiment analysis methods, for which we have taken a publication and tried to improve the results obtained and to propose new methods.&lt;/p&gt;

&lt;h5 id=&quot;results-by-month-for-joy-and-sadness-emotions-during-the-2017&quot;&gt;Results by month for joy and sadness emotions during the 2017&lt;/h5&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/mbenhamd/database-publication-latex/blob/master/monthly_analysis_joy_sadness-exemple.png?raw=true&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The complete archive was downloaded on &lt;a href=&quot;https://archive.org/details/twitterstream&quot;&gt;Archive.org&lt;/a&gt; for a total of 5,8 Terabytes of data and we count 1,7 billion of tweets. A simple collection of JSON grabbed from the general twitter stream, for the purposes of research, history, testing and memory. This is the Spritzer version, the most light and shallow of Twitter grabs. Unfortunately, we do not currently have access to the Sprinkler or Garden Hose versions of the stream. For some technical reasons, only English tweets were analysed. The email of the uploader &lt;a href=&quot;jscott@archive.org&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h5 id=&quot;what-do-we-conclude-&quot;&gt;What do we conclude ?&lt;/h5&gt;

&lt;p&gt;In this report we have presented a sentiment analysis tool on a Web interface. In one hand we used data from an archive and in the other hand we used real time stream analysis. Due to the absence of labelled data we couldn’t argue on reliability of data. This recent publication really question us about the limit on software engineering &lt;a href=&quot;http://www.inf.usi.ch/phd/lin/downloads/Lin2018a.pdf&quot;&gt;here&lt;/a&gt;, but they did not explored deep learning &lt;a href=&quot;https://www.researchgate.net/publication/320101315_Textmining_at_EmoInt-2017_A_Deep_Learning_Approach_to_Sentiment_Intensity_Scoring_of_English_Tweets&quot;&gt;here&lt;/a&gt; and what we could achieve with this learning techniques using neural network fully connected that we always only get better with time because of optimized function behind and great computation that we have due to GPU in aim to build deep learning classifier &lt;a href=&quot;https://reader.elsevier.com/reader/sd/94DCC5BBC6744B82108E1435810AE13BED6ED08D41531BA6CD0114B7355D4C44FEC2A6F8C55F0B14ABCFEFF5655CD608&quot;&gt;here&lt;/a&gt;. There are also other features for the real stream &lt;a href=&quot;https://twitter.yannistannier.io/#/realtime&quot;&gt;here&lt;/a&gt; such as geolocation of people, we could then generate a graph as a center to any user and know its impact on an interactive map, this would allow among other things to know the influence for example. To conclude, we think that having access to geolocation data and build a powerful neural network trained and design for sentiment analysis could be a great idea for future work.&lt;/p&gt;
</description>
                <pubDate>Mon, 23 Sep 2019 00:00:00 +0100</pubDate>
                <link>http://localhost:4000/twitter-sentiment-analysis</link>
                <guid isPermaLink="true">http://localhost:4000/twitter-sentiment-analysis</guid>
                
                <category>Twitter</category>
                
                <category>Sentiment Analysis</category>
                
                <category>Streaming</category>
                
                <category>Spark</category>
                
                
            </item>
        
            <item>
                <title>Twitter Sentiment Analysis with a CNN</title>
                <description>&lt;p&gt;&lt;em&gt;Presentation of a TensorFlow implementation of a CNN for Twitter Sentiment Analysis available on my &lt;a href=&quot;https://github.com/mbenhamd/twitter-sentiment-cnn&quot;&gt;Github repository&lt;/a&gt;&lt;/em&gt;:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Link of the publication : &lt;a href=&quot;https://github.com/mbenhamd/database-publication-latex/blob/master/publication.pdf&quot;&gt;here&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;We used those settings for training the CNN :&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Flags:
	batch_size = 128
	checkpoint_freq = 1
	custom_input = &quot;&quot;
	dataset_fraction = 1.0
	device = gpu
	embedding_size = 128
	epochs = 10
	evaluate_batch = False
	filter_sizes = 3,4,5
	load = None
	num_filters = 128
	save = True
	save_protobuf = False
	test_data_ratio = 0.1
	train = True
	valid_freq = 1

Dataset:
	Train set size = 1420766
	Test set size = 157862
	Vocabulary size = 274562
	Input layer size = 117
	Number of classes = 2

On a GTX 1060 (1280 cuda cores), we did 110 990 iterations (10 epochs)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;!--more--&gt;
&lt;p&gt;The CNN is about 424,1 Mo, it is a result of (round) 2h20 minute of computation with the GPU. At the end, the neural network comes up with a validation accuracy of 82%.&lt;/p&gt;

&lt;p&gt;Here some plot about the validation accuracy and training loss : &lt;img src=&quot;https://github.com/mbenhamd/twitter-sentiment-cnn/blob/master/validation-accuracy.png?raw=true&quot; alt=&quot;alt text&quot; title=&quot;Validation Accuracy&quot; /&gt; &lt;img src=&quot;https://github.com/mbenhamd/twitter-sentiment-cnn/blob/master/training-loss.png?raw=true&quot; alt=&quot;alt text&quot; title=&quot;Training Loss&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;It is based on a previous work of Daniele Grattarola&lt;/em&gt;&lt;/p&gt;

&lt;h6 id=&quot;description&quot;&gt;Description&lt;/h6&gt;

&lt;p&gt;This code is meant to have an educational value, to train the model by yourself and play with different configurations, and was not developed to be deployed as-is (although it has been used in &lt;a href=&quot;https://linkedin.com/pulse/real-time-twitter-sentiment-analytics-tensorflow-spring-tzolov/&quot;&gt;professional contexts&lt;/a&gt;). The dataset used for training is taken from &lt;a href=&quot;http://thinknook.com/twitter-sentiment-analysis-training-corpus-dataset-2012-09-22/&quot;&gt;here&lt;/a&gt; (someone reported to me that the link to the dataset appears to be dead sometimes, so &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dataset_downloader.py&lt;/code&gt; &lt;strong&gt;might&lt;/strong&gt; not work. I successfully ran the script on January 20, 2018, but please report it to me if you have any problems).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;NOTE: this script is for Python 2.7 only&lt;/strong&gt;&lt;/p&gt;

&lt;h6 id=&quot;setup&quot;&gt;Setup&lt;/h6&gt;

&lt;p&gt;You’ll need Tensorflow &amp;gt;=1.1.0 and its dependecies installed in order for the script to work (see &lt;a href=&quot;https://www.tensorflow.org/&quot;&gt;here&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Once you’ve installed and configured Tensorflow, download the source files and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cd&lt;/code&gt; into the folder:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;git clone https://gitlab.com/danielegrattarola/twitter-sentiment-cnn.git
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cd &lt;/span&gt;twitter-sentiment-cnn
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Before being able to use the script, some setup is needed; download the dataset from the link above by running:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;python dataset_downloader.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Read the dataset from the CSV into two files (.pos and .neg) with:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;python csv_parser.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And generate a CSV with the vocabulary (and its inverse mapping) with:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;python vocab_builder.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The files will be created in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;twitter-sentiment-dataset/&lt;/code&gt; folder. Finally, create an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;output/&lt;/code&gt; folder that will contain all session checkpoints needed to restore the trained models:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;mkdir &lt;/span&gt;output
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now everything is set up and you’re ready to start training the model.&lt;/p&gt;

&lt;h6 id=&quot;usage&quot;&gt;Usage&lt;/h6&gt;

&lt;p&gt;The simplest way to run the script is:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;python twitter-sentiment-cnn.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;which will load the dataset in memory, create the computation graph, and quit. Try to run the script like this to see if everything is set up correctly. To run a training session on the full dataset (and save the result so that we can reuse the network later, or perform more training) run:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;python twitter-sentiment-cnn.py &lt;span class=&quot;nt&quot;&gt;--train&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--save&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After training, we can test the network as follows:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;python twitter-sentiment-cnn.py &lt;span class=&quot;nt&quot;&gt;--load&lt;/span&gt; path/to/ckpt/folder/ &lt;span class=&quot;nt&quot;&gt;--custom_input&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'I love neural networks!'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;which will eventually output:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;...
Processing custom input: I love neural networks!
Custom input evaluation: POS
Actual output: [ 0.19249919  0.80750078]
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;By running:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;python twitter-sentiment-cnn.py &lt;span class=&quot;nt&quot;&gt;-h&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;the script will output a list of all customizable flags and parameters. The parameters are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;train&lt;/code&gt;: train the network;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;save&lt;/code&gt;: save session checkpoints;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;save_protobuf&lt;/code&gt;: save model as binary protobuf;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;evaluate_batch&lt;/code&gt;: evaluate the network on a held-out batch from the dataset and print the results (for debugging/educational purposes);&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;load&lt;/code&gt;: restore a model from the given path;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;custom_input&lt;/code&gt;: evaluate the model on the given string;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;filter_sizes&lt;/code&gt;: comma-separated filter sizes for the convolutional layers (default: ‘3,4,5’);&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dataset_fraction&lt;/code&gt;: fraction of the dataset to load in memory, to reduce memory usage (default: 1.0; uses all dataset);&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;embedding_size&lt;/code&gt;: size of the word embeddings (default: 128);&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;num_filters&lt;/code&gt;: number of filters per filter size (default: 128);&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;batch_size&lt;/code&gt;: batch size (default: 128);&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;epochs&lt;/code&gt;: number of training epochs (default: 3);&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;valid_freq&lt;/code&gt;: how many times per epoch to perform validation testing (default: 1);&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;checkpoint_freq&lt;/code&gt;: how many times per epoch to save the model (default: 1);&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;test_data_ratio&lt;/code&gt;: fraction of the dataset to use for validation (default: 0.1);&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;device&lt;/code&gt;: device to use for running the model (can be either ‘cpu’ or ‘gpu’).&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;pre-trained-model&quot;&gt;Pre-trained model&lt;/h6&gt;

&lt;p&gt;User &lt;a href=&quot;https://github.com/Horkyze&quot;&gt;@Horkyze&lt;/a&gt; kindly trained the model for three epochs on the full dataset and shared the summary folder for quick deploy. The folder is available on &lt;a href=&quot;https://mega.nz/#!xVg0ARYK!oVyBZatotQGOD_FFSzZl5gTS1Z49048vjFEbyzftcFY&quot;&gt;Mega&lt;/a&gt;, to load the model simply unpack the zip file and use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--load&lt;/code&gt; flag as follows:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;# Current directoty: twitter-sentiment-cnn/&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;unzip path/to/run20180201-231509.zip
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;python twitter-sentiment-cnn.py &lt;span class=&quot;nt&quot;&gt;--load&lt;/span&gt; path/to/run20180201-231509/ &lt;span class=&quot;nt&quot;&gt;--custom_input&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;I love neural networks!&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Running this command should give you something like:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;======================= START! ========================
	data_helpers: loading positive examples...
	data_helpers: [OK]
	data_helpers: loading negative examples...
	data_helpers: [OK]
	data_helpers: cleaning strings...
	data_helpers: [OK]
	data_helpers: generating labels...
	data_helpers: [OK]
	data_helpers: concatenating labels...
	data_helpers: [OK]
	data_helpers: padding strings...
	data_helpers: [OK]
	data_helpers: building vocabulary...
	data_helpers: [OK]
	data_helpers: building processed datasets...
	data_helpers: [OK]

Flags:
	batch_size = 128
	checkpoint_freq = 1
	custom_input = I love neural networks!
	dataset_fraction = 0.001
	device = cpu
	embedding_size = 128
	epochs = 3
	evaluate_batch = False
	filter_sizes = 3,4,5
	load = output/run20180201-231509/
	num_filters = 128
	save = False
	save_protobuf = False
	test_data_ratio = 0.1
	train = False
	valid_freq = 1

Dataset:
	Train set size = 1421
	Test set size = 157
	Vocabulary size = 274562
	Input layer size = 36
	Number of classes = 2

Output folder: /home/phait/dev/twitter-sentiment-cnn/output/run20180208-112402
Data processing OK, loading network...
Evaluating custom input: I love neural networks!
Custom input evaluation: POS
Actual output: [0.04109644 0.95890355]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;NOTE: loading this model won’t work if you change anything in the default network architecture, so don’t set the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--filter_sizes&lt;/code&gt; flag&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;According to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;log.log&lt;/code&gt; file provided by &lt;a href=&quot;https://github.com/Horkyze&quot;&gt;@Horkyze&lt;/a&gt;, the model had a final validation accuracy of 0.80976, and a validation loss of 53.3314.&lt;/p&gt;

&lt;p&gt;I sincerely thank &lt;a href=&quot;https://github.com/Horkyze&quot;&gt;@Horkyze&lt;/a&gt; for providing the computational power and sharing the model with me.&lt;/p&gt;

&lt;h6 id=&quot;model-description&quot;&gt;Model description&lt;/h6&gt;

&lt;p&gt;The network implemented in this script is a single layer CNN structured as follows:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Embedding layer&lt;/strong&gt;: takes as input the tweets (as strings) and maps each word to an n-dimensional space so that it is represented as a sparse vector (see &lt;a href=&quot;https://en.wikipedia.org/wiki/Word2vec&quot;&gt;word2vec&lt;/a&gt;).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Convolution layers&lt;/strong&gt;: a set of parallel 1D convolutional layers with the given filter sizes and 128 output channels. A filter’s size is the number of embedded words that the filter covers.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Pooling layers&lt;/strong&gt;: a set of pooling layers associated to each of the convolutional layers.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Concat layer&lt;/strong&gt;: concatenates the output of the different pooling layers into a single tensor.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Dropout layer&lt;/strong&gt;: performs neuron dropout (some neurons are randomly not considered during training).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Output layer&lt;/strong&gt;: fully connected layer with a softmax activation function to perform classification.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The script will automatically log the session with Tensorboard. To visualize the computation graph and training metrics run:&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;tensorboard &lt;span class=&quot;nt&quot;&gt;--logdir&lt;/span&gt; output/path/to/summaries/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;and then navigate to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;localhost:6006&lt;/code&gt; from your browser (you’ll see the computation graph in the &lt;em&gt;Graph&lt;/em&gt; section).&lt;/p&gt;
</description>
                <pubDate>Sun, 22 Sep 2019 00:00:00 +0100</pubDate>
                <link>http://localhost:4000/twitter-sentiment-analysis-with-a-cnn</link>
                <guid isPermaLink="true">http://localhost:4000/twitter-sentiment-analysis-with-a-cnn</guid>
                
                <category>Sentiment Analysis</category>
                
                <category>Twitter</category>
                
                <category>CNN</category>
                
                <category>Convolutional</category>
                
                <category>Neural Network</category>
                
                <category>Deep Learning</category>
                
                <category>Tensorflow</category>
                
                
            </item>
        
            <item>
                <title>Convolutional Autoencoder and clustering improvement</title>
                <description>&lt;p&gt;&lt;img src=&quot;https://github.com/mbenhamd/autoencodeur-convolutionel-extraction-caracteristiques/blob/master/auto-encoder-conv.PNG?raw=true&quot; alt=&quot;drawing&quot; width=&quot;auto&quot; max-width=&quot;100%&quot; height=&quot;100%&quot; /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Presentation of comparison of discrimination characteristic extraction models available on my &lt;a href=&quot;https://github.com/mbenhamd/autoencodeur-convolutionel-extraction-caracteristiques&quot;&gt;Github repository&lt;/a&gt;&lt;/em&gt;:&lt;/p&gt;

&lt;h3 id=&quot;abstract&quot;&gt;Abstract&lt;/h3&gt;

&lt;p&gt;In machine learning, feature extraction starts from of an initial set of measured data and constructs derived values (characteristics) intended to be informative and not redundant. This has as a consequence of facilitating the subsequent stages of learning and generalization by leading to better human interpretations. In this document, we will propose some visualization techniques and Data Reduction on the Fashion-MNIST Dataset in Combination with a learning model. &lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;The idea of auto-encoders was mentioned for the first time in 1986, in an article analyzing in depth the backpropagation. In the following years, the idea resurfaced in other documents of research. An article published in 1989 allowed to introduce further auto-encoders by putting in the ability to extract the characteristics linear. Subsequently, it was discovered that one could discover nonlinear factorial representations. In this context, we had as mini-project to make the comparison between the ACP and the auto-encoders to a complex data set somehow. Then we will try to visualize these results using a method clustering to see the consequences of encoding.&lt;/p&gt;

&lt;p&gt;We learned a lot through this mini project since it involves visualization and clustering techniques. We could also see the different characteristics of the auto-encoders and their variants. Following of the exercise on encoders, we found that auto-encoders could help us improve the results of clustering in the context of a dataset that we do not know the class or classes associated. Then the t-SNE will allow us to visualize the meaning of our data to through the distribution of points. In addition, we found that the divergence of Kullback-Leibler and its relationship with mutual information was useful to evaluate our results. For the rest, we could have built an architecture using a variational autoencoder in addition to the convolutional layers and then tried several parameters for K-means to retain the one that would have given us the best precision. Finally, it was a project that allowed us to explore, visualize and classify the dataset Fashion-MNIST which is more complex than MNIST.&lt;/p&gt;
</description>
                <pubDate>Sat, 21 Sep 2019 00:00:00 +0100</pubDate>
                <link>http://localhost:4000/convolutional-autoencoder-and-clustering-improvement</link>
                <guid isPermaLink="true">http://localhost:4000/convolutional-autoencoder-and-clustering-improvement</guid>
                
                <category>Autoencoder</category>
                
                <category>PCA</category>
                
                <category>t-SNE</category>
                
                <category>K-means</category>
                
                
            </item>
        
            <item>
                <title>Ensemble method applied to detection of financial fraud</title>
                <description>&lt;p&gt;&lt;img src=&quot;/ressources/ensemble-method/boxplot.png&quot; alt=&quot;drawing&quot; width=&quot;auto&quot; max-width=&quot;100%&quot; height=&quot;20%&quot; /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Presentation of ensemble method applied to Detection of financial fraud available on my &lt;a href=&quot;https://github.com/mbenhamd/methodes-ensemblistes-fraudes&quot;&gt;Github repository&lt;/a&gt;&lt;/em&gt;:&lt;/p&gt;

&lt;h6 id=&quot;abstract&quot;&gt;Abstract&lt;/h6&gt;

&lt;p&gt;Fraud represents a loss of turnover of several billion dollars and increases every year. The economic crime survey PwC global survey in 2018 revealed that half (49%) of the 7,200 respondents had been the victim of some type of fraud. It’s about of an increase over the 2016 PwC study in which a little more than one third of the organizations surveyed (36%) had been victims of economic crime. Traditional methods of data analysis have been used for a long time to detect fraud and it is in this context that we will carry out several ways to approach the problem in order to see the advantages and disadvantages of each learning model and the one that gives the best prediction results.
&lt;!--more--&gt;&lt;/p&gt;

&lt;h6 id=&quot;introduction&quot;&gt;Introduction&lt;/h6&gt;

&lt;p&gt;Techniques used to detect fraud require investigation complex and tedious then they deal with different areas of knowledge such as finance, economics. Here are some examples of statistical data analysis techniques:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Pre-processing techniques for detecting, validating, correcting errors and filling missing data or incorrect.&lt;/li&gt;
  &lt;li&gt;Calculation of various statistical parameters such as averages, quantiles, performance measures, probability distributions, etc.&lt;/li&gt;
  &lt;li&gt;Chronological analysis of time-dependent data (time series).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/ressources/ensemble-method/features.png&quot; alt=&quot;alt text&quot; title=&quot;MNIST Sample&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In our case, we will use models of supervised learning and we will not use clustering methods. This type of model only detects frauds similar to those that took place previously and were classified by a human. Regarding the detection of fraud by credit card payment, the problem of ranking involves the creation of sufficiently intelligent models to properly classify transactions into legitimate transactions or fraudulent, depending on the details of the transaction such as the amount, the trader, the location, the time and others.&lt;/p&gt;

&lt;h6 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h6&gt;

&lt;p&gt;To conclude, we have been very interested in the set-up methods in our approach to this problem in order to be original. The decision tree-based methods are interesting because model architecture reduces over-fitting, but poor sampling practices can lead to misleading conclusions the quality of a model. The main purpose of model validation is to estimate how whose model will generalize to new data. If the decision to put a model in production depends on how it works on a validation set, it is essential that the oversampling be performed correctly. In fact, by oversampling only the training data, none of the information contained in the validation data is used to create synthetic observations therefore, these results should be generalizable. Then oversampling is a well-known way to potentially improve the models formed on unbalanced data but it is important to remember that incorrect oversampling can lead to think that a model will generalize better than it actually does. Our results may seem weak compared to what is available on the internet but it is appropriate to use cross validation correctly with good sampling method as well as an appropriate metric when our data is out of balance.&lt;/p&gt;
</description>
                <pubDate>Fri, 20 Sep 2019 00:00:00 +0100</pubDate>
                <link>http://localhost:4000/ensemble-method-applied-to-detection-of-financial-fraud</link>
                <guid isPermaLink="true">http://localhost:4000/ensemble-method-applied-to-detection-of-financial-fraud</guid>
                
                <category>Ensemble Method</category>
                
                <category>SMOTE</category>
                
                <category>Imbalanced Dataset</category>
                
                
            </item>
        
            <item>
                <title>Mixture models applied to usual image data</title>
                <description>&lt;p&gt;&lt;img src=&quot;https://github.com/mbenhamd/mixture-model-images/blob/master/plot/show_images_mnist.png?raw=true&quot; alt=&quot;drawing&quot; width=&quot;auto&quot; max-width=&quot;100%&quot; height=&quot;25%&quot; /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Presentation of mixture models applied to usual image data available on my &lt;a href=&quot;https://github.com/mbenhamd/mixture-model-images&quot;&gt;Github repository&lt;/a&gt;&lt;/em&gt;:&lt;/p&gt;

&lt;h6 id=&quot;abstract&quot;&gt;Abstract&lt;/h6&gt;

&lt;p&gt;Mixture models are routinely used to extract features from speech data, but also in object detection from images. By deducing parameters from the distribution of the data, they make it possible to predict the location of the objects with each image of a video sequence. The Gaussian mixing model is a probabilistic model that will be used to represent normally distributed subpopulations within a global population. Mixing models in general do not require knowing which subpopulation belongs to a data point, which allows the model to automatically learn subpopulations. As the assignment of subpopulations is not known, it is a form of unsupervised learning.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h6 id=&quot;introduction&quot;&gt;Introduction&lt;/h6&gt;

&lt;p&gt;The classification of images is one of the major challenges of image processing and computer vision. However, the application of mixture models applied to segmentation presents some difficulties. For the classic blend statistical model, each pixel must be associated with exactly one class. This hypothesis may not be realistic. So, several methods have been proposed to work around this problem (such as fuzzy classification). This approach gives satisfactory results in many cases, but in most cases the assumption of a single Gaussian generally limits the accuracy of the model. We will use the EM algorithm to estimate the parameters of Gaussian mixtures. Then the Gaussian mixing model is a flexible probabilistic model and a powerful modeling tool. It can be used to provide a group-based model in the area of ​​pattern recognition. However, the application presents some difficulties since it is sensitive to noise.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/mbenhamd/mixture-model-images/blob/master/plot/pca_eig_mnist5.png?raw=true&quot; alt=&quot;alt text&quot; title=&quot;MNIST Sample&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/mbenhamd/mixture-model-images/blob/master/plot/t-sne_mnist_mm.png?raw=true&quot; alt=&quot;alt text&quot; title=&quot;MNIST Sample&quot; /&gt;&lt;/p&gt;

&lt;h6 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h6&gt;

&lt;p&gt;In this project, we made a lot of comparisons between the 5 different datasets. We have seen several types of classification methods (hierarchical ascending classification, partitioning with Kmeans) but we have been able to explore the models of mixtures in several ways. Indeed, we have noticed that factor analysis methods can help to learn a mixing model without having to envy auto-encoders, but finally the temporal complexity of them leaves something to be desired. Moreover the mathematics behind the mix models are more difficult to access and therefore less attractive to the general public. The project was very informative as we were able to implement many methods from unsupervised learning.&lt;/p&gt;
</description>
                <pubDate>Wed, 18 Sep 2019 00:00:00 +0100</pubDate>
                <link>http://localhost:4000/mixture-models-applied-to-usual-image-data</link>
                <guid isPermaLink="true">http://localhost:4000/mixture-models-applied-to-usual-image-data</guid>
                
                <category>Mixture Models</category>
                
                <category>Image Analaysis</category>
                
                <category>Unsupervised Learning</category>
                
                
            </item>
        
            <item>
                <title>Multi Agent System Project</title>
                <description>&lt;p&gt;&lt;img src=&quot;https://github.com/mbenhamd/twitter-analysis-mas/blob/master/app-screenshot.png?raw=true &quot; alt=&quot;drawing&quot; width=&quot;auto&quot; max-width=&quot;100%&quot; height=&quot;auto&quot; /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Presentation of a Multi Agent System Project available on my &lt;a href=&quot;https://github.com/mbenhamd/twitter-analysis-mas&quot;&gt;Github repository&lt;/a&gt;&lt;/em&gt;:&lt;/p&gt;

&lt;p&gt;It’s an application using JADE Framework with Swing for the graphical interface.
The aim is to analyse sentiment between a conversation between two agents.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;At the end of the conversation, we do the confusion matrix after the sentiment analysis using Indico API &lt;a href=&quot;https://indico.io/&quot;&gt;Website here&lt;/a&gt;.&lt;/p&gt;
</description>
                <pubDate>Tue, 17 Sep 2019 00:00:00 +0100</pubDate>
                <link>http://localhost:4000/multi-agent-system-twitter</link>
                <guid isPermaLink="true">http://localhost:4000/multi-agent-system-twitter</guid>
                
                <category>Multi Agent System</category>
                
                <category>Twitter</category>
                
                <category>Sentiment Analysis</category>
                
                
            </item>
        
            <item>
                <title>Reinforcement learning benchmark</title>
                <description>&lt;p&gt;&lt;img src=&quot;https://softwareengineeringdaily.com/wp-content/uploads/2018/06/OpenAI.png&quot; alt=&quot;drawing&quot; width=&quot;auto&quot; max-width=&quot;100%&quot; height=&quot;auto&quot; /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Presentation of a comparison of different reinforcement learning algorithms available on my &lt;a href=&quot;https://github.com/mbenhamd/reinforcement-learning-benchs&quot;&gt;Github repository&lt;/a&gt;&lt;/em&gt;:&lt;/p&gt;

&lt;p&gt;Reinforcement Learning (RA) is about learning what to do, how to relate actions to situations, and how to maximize a reward. The learner is not told what action to take, but instead he must find out which actions give the most reward by trying them. In the most interesting case, actions can affect not only the immediate rewards but also the next situation, and hence the longer term rewards. These two properties - trial-and-error and long-term reward - are the two most important features of reinforcement learning.
&lt;!--more--&gt;&lt;/p&gt;

&lt;h6 id=&quot;agent-oriented-learning&quot;&gt;Agent Oriented Learning&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Mini-project: Comparison of different reinforcement learning algorithms.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We will use the library &lt;strong&gt;Open IA Gym&lt;/strong&gt; including many games so we can then develop an AI able to learn to maximize its score.&lt;/p&gt;

&lt;p&gt;The game we will use is “N-chain”.&lt;/p&gt;

&lt;p&gt;This game presents movements along a linear chain of states, with two actions: forward, which moves along the chain but gives no reward back, which returns to the start and has a small reward. The end of the chain, however, offers a great reward, and moving forward to the end of the chain, this important reward can be repeated.&lt;/p&gt;

&lt;p&gt;At each action, there is a low probability that the agent “slips” and the opposite transition is taken instead.&lt;/p&gt;

&lt;p&gt;The observed state is the current state in the chain (0 to n-1).&lt;/p&gt;

&lt;p&gt;The game was designed and used by Malcolm J. A. Strens: &lt;a href=&quot;http://ceit.aut.ac.ir/~shiry/lecture/machine-
learning/papers/BRL-2000.pdf&quot;&gt;A Bayesian Framework for Reinforcement Learning&lt;/a&gt;&lt;/p&gt;
</description>
                <pubDate>Sun, 15 Sep 2019 00:00:00 +0100</pubDate>
                <link>http://localhost:4000/reinforcement-learning-algorithms-comparaison</link>
                <guid isPermaLink="true">http://localhost:4000/reinforcement-learning-algorithms-comparaison</guid>
                
                <category>Reinforcement Learning</category>
                
                <category>Q-Learning</category>
                
                <category>TD-Learning</category>
                
                <category>Double Q-learning</category>
                
                <category>Keras</category>
                
                <category>Open IA Gym</category>
                
                
            </item>
        
            <item>
                <title>Quality of documents embeddings</title>
                <description>&lt;p&gt;&lt;img src=&quot;https://github.com/mbenhamd/documents-embeddings/blob/master/word-cloud-exemple.PNG?raw=true&quot; alt=&quot;drawing&quot; width=&quot;auto&quot; max-width=&quot;100%&quot; height=&quot;auto&quot; /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Presentation of quality of embeddings documents available on my &lt;a href=&quot;https://github.com/mbenhamd/documents-embeddings&quot;&gt;Github repository&lt;/a&gt;&lt;/em&gt;:&lt;/p&gt;

&lt;h6 id=&quot;abstract&quot;&gt;Abstract&lt;/h6&gt;

&lt;p&gt;Text Mining is a branch of Data Mining that specializes in text corpus processing to analyze the content and extract it knowledge. In our case, the objective is to evaluate the quality of a set of embedding dies that represent documents. We will perform a clustering on documents and will compare the values of clustering with different evaluation criteria.
&lt;!--more--&gt;&lt;/p&gt;

&lt;h6 id=&quot;introduction&quot;&gt;Introduction&lt;/h6&gt;

&lt;p&gt;Paragraph vectors (Doc2Vec) have recently been proposed as unsupervised method for learning documents. In their works, the authors showed that the method can learn to integrate Movie review texts that can be used for sentiment analysis. This proof of concept, while encouraging, was rather narrow. Indeed, the word embedding has opened new perspectives across a reduction in dimensionality and a new vision of words (a semantic vision). In the same way the document embedding is an extension brought when the number of documents becomes important and we seek to have a result of similarity, then be able to classify and have a technique to discriminate documents (e.g., books of mechanics and Botanical). Here we consider tasks other than the analysis of feelings, we use two datasets (Class3 and Reut8) with other analysis algorithms, such as the NMF and the LSA to evaluate the quality of their embeddings. Then we will evaluate the performances to see what are the strengths and weaknesses of the different analyzes.&lt;/p&gt;

&lt;h6 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h6&gt;

&lt;p&gt;As part of this project we learned a lot about the methods such as the LSA, NMF as well as Doc2Vec. Each method seen in these projects has strong and weak points like how fast the LSA does to Doc2Vec and the NMF, or the ability of the NMF to have a decomposition taking into account the weight of each cluster and thus to be more easily interpretable following each column of the matrix W then the LSA had an ability to retrieve the different meanings of the words. Then we realized without real surprise that Doc2Vec was the method bringing the best results knowing that we can load a pre-trained model on a very large dataset to be able to transfer knowledge (in other words, initialize the weights of the neural network), this which lets us think that this is a very promising method. Doc2Vec appears as an ideal method in itself, even if they are classic data sets, we could see that the defects of Reters8 were able to to be exceeded by modifying the algorithm through the two approaches of this method. This project allowed us to use several popular python library, with their lots of varieties and to be able to analyze and model our games of data as well as learning in many ways. We could have improved the results on the datasets by performing further pre-processing, but the purpose of this project was rather to evaluate quality in a general way without being specific according to the context of the data.&lt;/p&gt;
</description>
                <pubDate>Fri, 13 Sep 2019 00:00:00 +0100</pubDate>
                <link>http://localhost:4000/quality-of-documents-embeddings</link>
                <guid isPermaLink="true">http://localhost:4000/quality-of-documents-embeddings</guid>
                
                <category>NMF</category>
                
                <category>LSA</category>
                
                <category>Doc2Vec</category>
                
                <category>Data Mining</category>
                
                
            </item>
        
            <item>
                <title>Non-negative matrix factorization and image classification</title>
                <description>&lt;p&gt;&lt;img src=&quot;https://www.researchgate.net/profile/Hongping_Cai/publication/290324486/figure/fig4/AS:613900601012249@1523376717327/Our-photo-art-dataset-containing-50-object-categories-Each-category-is-displayed-with.png&quot; alt=&quot;drawing&quot; width=&quot;auto&quot; max-width=&quot;100%&quot; height=&quot;auto&quot; /&gt;
&lt;br /&gt;
&lt;em&gt;Presentation of a Non-negative matrix factorization and image classification project available on my &lt;a href=&quot;https://github.com/mbenhamd/nmf-ter&quot;&gt;Github repository&lt;/a&gt; and a french presentation available &lt;a href=&quot;https://github.com/mbenhamd/ter-presentation-beamer&quot;&gt;here&lt;/a&gt;&lt;/em&gt;:&lt;/p&gt;

&lt;h6 id=&quot;abstract&quot;&gt;Abstract&lt;/h6&gt;

&lt;p&gt;Automatic classification or clustering consists of partioning a set of objects (instances) described by a set of variables into homogeneous groups (classes). With the advent of Big Data and data science, clustering has become a very important task in various fields including imaging. The images are very widespread data especially on the web and social networks (Instagram, Pinterest, Flickr, Google, etc …). The goal will be to propose a classification system for images from various databases (photos , paintings, comics, etc.). The non-negative matrix factorization makes it possible to approximate a positive data matrix by the product of two matrices of lower and positive dimensions. By its simplicity, this method has become popular and is used both in size reduction and also in clustering in a user-defined number of classes k. &lt;!--more--&gt;&lt;/p&gt;

&lt;h6 id=&quot;data-set&quot;&gt;Data Set&lt;/h6&gt;

&lt;p&gt;We used this data set from : &lt;a href=&quot;https://github.com/BathVisArtData/PeopleArt&quot;&gt;People Art&lt;/a&gt;&lt;/p&gt;

&lt;h6 id=&quot;example&quot;&gt;Example&lt;/h6&gt;

&lt;p&gt;&lt;strong&gt;Explained variance for SepNMF with Spherical K-means using Norm L2 (rank = [20;70]).&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/mbenhamd/nmf-ter/blob/master/nmf_result/sepnmf-norm-2-skmeans--EVAR.png?raw=true&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h6 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h6&gt;

&lt;p&gt;To conclude we will discuss the cases that we have not treated and the data set itself, clustering is a very complicated area because we travel in the vagueness as we have seen during this semester but we learned a lot about automatic classification. First of all, we gave the different results and their explanation but that taught us several very useful things as data science students. Even with thoughtful pre-processing or without, ultimately the results were bad as well as a multitude of different combinations of the NMF (algorithms, methods, initializations) will not change the facts. The problem comes from the data set which is in itself not adapted and corresponds to the weak points of the NMF. The coefficients are positive numbers, but for every vector in the database, the amount of information is usually a small part that we use to reconstruct our points. Lines with too much variety in themselves do not allow the NMF to find a pattern. In particular, it must be realized that while the NMF is widely used in science, its rigorous foundation has only been discovered for less than 30 years. At the moment we are writing and it is very likely that we have not yet found the best algorithm for this. Then, we faced a lack of time to perform the analyzes with a RGB and binary matrix. You should know that we used two different services of Cloud Computing (Amazon Web Service, Google Cloud Computing) , libraries Nimfa and NMF for R uses the CPU while for calculations Matrix intensive, a minimum is to use the GPU to drastically reduce the calculation time. All the resources (graphics, scripts) of the project are available &lt;a href=&quot;https://github.com/mbenhamd/nmf-ter&quot;&gt;here&lt;/a&gt;. Finally, since the data set was built for cross-depiction, we can say that the NMF as a technique is not suitable for this problem (other solutions exist such as convectional neural networks or Deep Semi-NMF.&lt;/p&gt;

&lt;h6 id=&quot;keywords&quot;&gt;Keywords&lt;/h6&gt;

&lt;p&gt;Unsupervised Learning, Spherical K-means, Scikit-Learn, Nimfa, Python, R, People-Art Dataset&lt;/p&gt;
</description>
                <pubDate>Thu, 12 Sep 2019 00:00:00 +0100</pubDate>
                <link>http://localhost:4000/non-negative-matrix-factorization-and-image-classification</link>
                <guid isPermaLink="true">http://localhost:4000/non-negative-matrix-factorization-and-image-classification</guid>
                
                <category>Unsupervised Learning</category>
                
                <category>Image Analaysis</category>
                
                <category>NMF</category>
                
                
            </item>
        
            <item>
                <title>Visualisation method applied on genomic data</title>
                <description>&lt;p&gt;&lt;img src=&quot;https://github.com/mbenhamd/exploration-visuelles-genomique/blob/master/lle_exemple.PNG?raw=true&quot; alt=&quot;drawing&quot; width=&quot;auto&quot; max-width=&quot;100%&quot; height=&quot;auto&quot; /&gt;
&lt;br /&gt;
&lt;em&gt;Presentation of visual exploration of genomic data available on my &lt;a href=&quot;https://github.com/mbenhamd/exploration-visuelles-genomique&quot;&gt;Github repository&lt;/a&gt;&lt;/em&gt;:&lt;/p&gt;

&lt;h6 id=&quot;abstract&quot;&gt;Abstract&lt;/h6&gt;

&lt;p&gt;Interpretation and visual exploration of data from multidimensional data sets can be a real headache for the human. While the 2D / 3D datasets are very easy to display: it is easy to represent the inherent structure of their data, it is not easy to perform intuitive visualization for large data sets. In order to improve the visualization and interpretation capacity of these large multidimensional data sets, the should be reduced while trying to keep as much information as possible. The purpose of the methods presented in this paper are twofold: to realize a reduction of the dimension by extraction of characteristics but also allow the visual interpretation of the information kept &lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;We will study current visualization techniques as well as techniques for reducing dimension to improve learning and its interpretation. It should be remembered that the family methods of data analysis can be subdivided into two families of methods:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Linear: The axes used are linear combinations of the initial variables. These algorithms try to choose the linear projection “optimal / interesting” points on a vector space reduced. They can be powerful, but do not take into account nonlinear structures in the data.&lt;/li&gt;
  &lt;li&gt;Non-linear: Most of these methods are based on the notion of neighborhood, with graphs, or simply linear combination of neighbors. These methods are more sensitive to the structures non-linear data and tries to preserve the global / local properties of the data. These two types of methods are based both on the idea that the size of many The data is often artificially high and can be reduced without raising a loss. significant information. At first we will present in a rather brief way each of the algorithms used, then we will perform a comparative study of some linear and non-linear dimension reduction algorithms on datasets: Gordon and Pomeroy.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In this project, we discussed different techniques used for visualization and analysis Datas. These techniques can be used to reduce multivariate data dimensions explanatory notes and their classification. We noticed the ACP can be useful for decorrelating variables initial and thus be used for an ADL. It has also been noted that the LDA due to this knowledge classes, works wonders, although it can not capture nonlinear phenomena. The PCR used as initialization for ADL facilitates interpretation and improves results in certain cases. the ACP looks for relationships between variables while the MDS looks for similarities between observations so that we can interpret the axes of the PCA using the variables while the MDS does not allow it (simply because there are no more variables). MDS therefore remains more a method of reducing dimension than visualization. For LLE and Isomap, we varied the number of neighbors to the nearest maximum for each datasets because it remains extremely weak. Isomap tends to have a cloud of points where the classes are separated and dense whereas the LLE will tend to search locally for each particularity individuals and gives a scatter when viewing each individual while remaining readable. Finally, this project allowed us to realize several techniques seen in progress on two datasets where the number of observation observations were extremely low compared to the variables.&lt;/p&gt;
</description>
                <pubDate>Mon, 09 Sep 2019 00:00:00 +0100</pubDate>
                <link>http://localhost:4000/visualisation-method-applied-on-genomic-data</link>
                <guid isPermaLink="true">http://localhost:4000/visualisation-method-applied-on-genomic-data</guid>
                
                <category>Visualisation</category>
                
                <category>PCA</category>
                
                <category>MDS</category>
                
                <category>Isomap</category>
                
                <category>LLE</category>
                
                <category>LDA</category>
                
                
            </item>
        
            <item>
                <title>Automatic classification of data temporal in ordered classes</title>
                <description>&lt;p&gt;&lt;img src=&quot;https://camo.githubusercontent.com/c27c4de4fa9dadfff3171d6af1f72f2208f2bd00/687474703a2f2f6372736f757a612e636f6d2f77702d636f6e74656e742f75706c6f6164732f323031322f30312f696d6167655f7468756d622d32353235354231362d3235323535442e706e67&quot; alt=&quot;drawing&quot; width=&quot;auto&quot; max-width=&quot;100%&quot; height=&quot;auto&quot; /&gt;
&lt;br /&gt;
&lt;em&gt;Presentation of automatic classification of data temporal in ordered classes available on my &lt;a href=&quot;https://github.com/mbenhamd/series-temporelles-fisher&quot;&gt;Github repository&lt;/a&gt;&lt;/em&gt;:&lt;/p&gt;

&lt;h6 id=&quot;abstract&quot;&gt;Abstract&lt;/h6&gt;

&lt;p&gt;Automatic classification or clustering consists of partioning a set of objects (instances) described by a set of variables in homogeneous groups (classes). It turns out that for some data, these are a sequence of numerical values ​​representing the evolution of a specific quantity over time, hence the notion of time series. The aim will be to propose a classification system from various datasets using Fisher’s dynamic algorithm and to see its effectiveness by comparing it to other methods.
&lt;!--more--&gt;&lt;/p&gt;

&lt;h6 id=&quot;introduction&quot;&gt;Introduction&lt;/h6&gt;

&lt;p&gt;As part of our school curriculum, we are required to carry out a project concerning unsupervised learning. The objective of this project is to study a clustering method that searches for ordered classes in a timeline. Fisher’s dynamic programming method is used for segmentation of time signals, or for change detection in a data sequence. In speech recognition systems, for example, this type is exploited. method for partitioning audio signals into associated time ranges to different speakers who are then identified. More generally, organizing a sequence of data into homogeneous segments is a process that helps to better organize them.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ressources/time-series/data.png&quot; alt=&quot;alt text&quot; title=&quot;MNIST Sample&quot; /&gt;&lt;/p&gt;

&lt;h6 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h6&gt;

&lt;p&gt;This non-superimposed learning project allowed us to implement Fisher’s dynamic programming algorithm and compare it to the CAH and K-means. We could see that Fisher’s algorithm is clearly appropriate within the framework of time series since it takes into account the temporality of data while K-Means and CAH Ward have a spatial approach. Indeed these two other methods look at the datasets as a set of points in a space with one or more dimensions without taking into account the temporal criterion. Even though we have some optimizations thanks to the use of appropriate package, we have as prospects to see the efficiency of the algorithm on a GPU (more appropriate component for the intensive matrix computation) because when we are dealing with larger data sets it is very likely that the nonlinear complexity of the algorithm poses a big problem.&lt;/p&gt;
</description>
                <pubDate>Sat, 07 Sep 2019 00:00:00 +0100</pubDate>
                <link>http://localhost:4000/automatic-classification-of-data-temporal-in-ordered-classes</link>
                <guid isPermaLink="true">http://localhost:4000/automatic-classification-of-data-temporal-in-ordered-classes</guid>
                
                <category>R</category>
                
                <category>Time series</category>
                
                <category>Unsupervised Learning</category>
                
                <category>Dynamic Programming</category>
                
                
            </item>
        
            <item>
                <title>Decision Tree From Scratch</title>
                <description>&lt;p&gt;&lt;img src=&quot;https://camo.githubusercontent.com/c27c4de4fa9dadfff3171d6af1f72f2208f2bd00/687474703a2f2f6372736f757a612e636f6d2f77702d636f6e74656e742f75706c6f6164732f323031322f30312f696d6167655f7468756d622d32353235354231362d3235323535442e706e67&quot; alt=&quot;drawing&quot; width=&quot;auto&quot; max-width=&quot;100%&quot; height=&quot;auto&quot; /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Presentation of a Decision Tree From Scratch available on my &lt;a href=&quot;https://github.com/mbenhamd/decision-tree-scratch&quot;&gt;Github repository&lt;/a&gt;&lt;/em&gt;:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;This repository was created as part of a course application:&lt;/em&gt; &lt;a href=&quot;http://www.math-info.univ-paris5.fr/~bouzy/Doc/AA1/InductionDecisionTree.pdf&quot;&gt;ici&lt;/a&gt;
&lt;!--more--&gt;&lt;/p&gt;

&lt;h6 id=&quot;introduction&quot;&gt;Introduction&lt;/h6&gt;

&lt;p&gt;Decision trees are a method used in machine learning to perform the &lt;strong&gt;classification&lt;/strong&gt; and &lt;strong&gt;prediction&lt;/strong&gt; of many phenomena such as weather events for example.&lt;/p&gt;

&lt;p&gt;They are popular because the &lt;strong&gt;final model&lt;/strong&gt; is easy to understand by practitioners and experts in the field of supervised learning. The final decision tree can explain exactly why a specific &lt;strong&gt;prediction&lt;/strong&gt; has been made, which makes it very attractive for operational use.&lt;/p&gt;

&lt;p&gt;Decision trees also provide the basis for more advanced ensemble methods such as &lt;strong&gt;random forests&lt;/strong&gt; (Random Forest).&lt;/p&gt;

&lt;p&gt;A script generating a data set has been put in place.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://crsouza.com/wp-content/uploads/2012/01/image_thumb-25255B16-25255D.png&quot; alt=&quot;alt text&quot; title=&quot;Exemple&quot; /&gt;&lt;/p&gt;
</description>
                <pubDate>Thu, 05 Sep 2019 01:00:00 +0100</pubDate>
                <link>http://localhost:4000/decision-tree-from-scratch</link>
                <guid isPermaLink="true">http://localhost:4000/decision-tree-from-scratch</guid>
                
                <category>Multi Agent System</category>
                
                <category>Twitter</category>
                
                <category>Sentiment Analysis</category>
                
                
            </item>
        
            <item>
                <title>Mini-project: Binero (or Takuzu)</title>
                <description>&lt;p&gt;&lt;img src=&quot;/ressources/binero/welcome.jpg&quot; alt=&quot;drawing&quot; width=&quot;auto&quot; max-width=&quot;100%&quot; height=&quot;auto&quot; /&gt;
&lt;br /&gt;
&lt;em&gt;Presentation of the game available on my &lt;a href=&quot;https://github.com/mbenhamd/Binero&quot;&gt;Github repository&lt;/a&gt;&lt;/em&gt;:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Takuzu&lt;/strong&gt; is a puzzle game from Japan. It is based on logic a bit like sudoku. It is usually a 10x10 or 8x8 grid, containing only 1s and 0s, which must be completed according to three rules:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;as many as 1 and 0 on each line and on each column.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;no more than 2 identical digits side by side.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;2 rows or 2 columns can not be identical.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Takuzu&lt;/strong&gt; is also known as Binero or Bento.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;After this quick presentation of the game, we agree that the game is a certain simplicity to implement in its basic version. For this we will describe later the structure of the game and the algorithms describing the rules of the game.&lt;/p&gt;

&lt;p&gt;Throughout this documentation it should be noted that the language used is C.&lt;/p&gt;

&lt;p&gt;The basic Binero object:&lt;/p&gt;
&lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grille&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;taille&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;A binero is composed of a grid composed of 0 or 1 and a whole size.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/ressources/binero/ingame.png&quot; alt=&quot;alt text&quot; title=&quot;Exemple of a game execution&quot; /&gt;&lt;/p&gt;
</description>
                <pubDate>Tue, 03 Sep 2019 00:00:00 +0100</pubDate>
                <link>http://localhost:4000/binero/</link>
                <guid isPermaLink="true">http://localhost:4000/binero/</guid>
                
                <category>Project</category>
                
                <category>Algorithmic</category>
                
                <category>C</category>
                
                
            </item>
        
            <item>
                <title>R Project with Cereals Food Dataset</title>
                <description>&lt;p&gt;&lt;img src=&quot;/ressources/r-food/cercle_correlation.png&quot; alt=&quot;drawing&quot; width=&quot;auto&quot; max-width=&quot;100%&quot; height=&quot;auto&quot; /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Presentation of a R project to introduce data science available on my &lt;a href=&quot;https://github.com/mbenhamd/cereals-data-project&quot;&gt;Github repository&lt;/a&gt;&lt;/em&gt;:&lt;/p&gt;

&lt;p&gt;The file provided is a summary of the nutritional characteristics of 77 cereals present in the majority of American businesses.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;The dataset processed in this project focuses on the main industrially produced grain products that have been on sale in US stores in recent years. Food and especially the “Healthy Food” remain a major concern for many people nowadays, some states even encourage their people to consume better but also more reasonably to reduce the health risks associated with a consumption greater than the daily needs means recommended by WHO. Current research indicates that adults should not consume more than 30% of their calories as fat, they would also need about 50 to 65 grams of protein per day and should provide the rest of their calorie intake by consuming carbohydrates. These figures given by way of example are to be modulated according to the sex, the age but also the physical activity of the targeted person. A recommended diet should also contain 20 to 35 grams of dietary fiber.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/mbenhamd/cereals-data-project/blob/master/pourcentage_variance_cumuler.PNG?raw=true&quot; alt=&quot;alt text&quot; title=&quot;PCA&quot; /&gt;&lt;/p&gt;
</description>
                <pubDate>Sun, 01 Sep 2019 00:00:00 +0100</pubDate>
                <link>http://localhost:4000/r-food/</link>
                <guid isPermaLink="true">http://localhost:4000/r-food/</guid>
                
                <category>Project</category>
                
                <category>R</category>
                
                <category>Statistics</category>
                
                
            </item>
        
    </channel>
</rss>