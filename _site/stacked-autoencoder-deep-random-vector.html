<!DOCTYPE html>
<html lang="en-US">
<head>
  <meta name="google-site-verification" content="jk_P6ub99gOREVqLFGd54Xe1Dgp57gAS248_qlRzIJg" />
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>[Paper Presentation] Stacked Autoencoder Based Deep Random Vector Functional Link Neural Network for Classification</title>
  <meta name="description" content="Extreme learning machine (ELM), which can be viewed as a variant of Random Vector Functional Link (RVFL) network without the input-output direct connections,...">
  <link rel="canonical" href="http://localhost:4000/stacked-autoencoder-deep-random-vector">
  <link rel="alternate" type="application/rss+xml" title="Artificial Mind Blog. Feed"
    href="http://localhost:4000/feed.xml">
  
  <!-- Styles -->
  <link href="https://fonts.googleapis.com/css?family=Lato:400,400i,700,700i%7CNoto+Serif:400,400i,700,700i&display=swap" rel="stylesheet">
  <link href="/assets/css/style.css" rel="stylesheet">
  <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>[Paper Presentation] Stacked Autoencoder Based Deep Random Vector Functional Link Neural Network for Classification | Artificial Mind Blog.</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="[Paper Presentation] Stacked Autoencoder Based Deep Random Vector Functional Link Neural Network for Classification" />
<meta name="author" content="Mohamed BEN HAMDOUNE" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Extreme learning machine (ELM), which can be viewed as a variant of Random Vector Functional Link (RVFL) network without the input-output direct connections, has been extensively used to create multi-layer (deep) neural networks. Such networks employ randomization based autoencoders (AE) for unsupervised feature extraction followed by an ELM classifier for final decision making." />
<meta property="og:description" content="Extreme learning machine (ELM), which can be viewed as a variant of Random Vector Functional Link (RVFL) network without the input-output direct connections, has been extensively used to create multi-layer (deep) neural networks. Such networks employ randomization based autoencoders (AE) for unsupervised feature extraction followed by an ELM classifier for final decision making." />
<link rel="canonical" href="http://localhost:4000/stacked-autoencoder-deep-random-vector" />
<meta property="og:url" content="http://localhost:4000/stacked-autoencoder-deep-random-vector" />
<meta property="og:site_name" content="Artificial Mind Blog." />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-10-15T00:00:00+01:00" />
<meta name="google-site-verification" content="jk_P6ub99gOREVqLFGd54Xe1Dgp57gAS248_qlRzIJg" />
<script type="application/ld+json">
{"@type":"BlogPosting","headline":"[Paper Presentation] Stacked Autoencoder Based Deep Random Vector Functional Link Neural Network for Classification","dateModified":"2019-10-15T00:00:00+01:00","datePublished":"2019-10-15T00:00:00+01:00","url":"http://localhost:4000/stacked-autoencoder-deep-random-vector","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/stacked-autoencoder-deep-random-vector"},"author":{"@type":"Person","name":"Mohamed BEN HAMDOUNE"},"description":"Extreme learning machine (ELM), which can be viewed as a variant of Random Vector Functional Link (RVFL) network without the input-output direct connections, has been extensively used to create multi-layer (deep) neural networks. Such networks employ randomization based autoencoders (AE) for unsupervised feature extraction followed by an ELM classifier for final decision making.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

</head>
<body>

  <div id="page" class="site">
    <div class="inner">
      <header class="site-header">
  
  <p class="site-title"><a class="logo-text" href="/">Artificial Mind Blog.</a></p>
  
  <nav class="site-navigation">
    <div class="site-navigation-wrap">
      <h2 class="screen-reader-text">Main navigation</h2>
      <ul class="menu">
        
        
        
        <li class="menu-item ">
          <a class="" href="/">Home</a>
        </li>
        
        
        
        <li class="menu-item ">
          <a class="" href="/curriculum-vitae/">Curriculum Vitae</a>
        </li>
        
        
        
        <li class="menu-item ">
          <a class="" href="/tags/">Archive</a>
        </li>
        
        
        
        <li class="menu-item ">
          <a class="" href="/about/">About</a>
        </li>
        
      </ul><!-- .menu -->
      <button id="menu-close" class="menu-toggle"><span class="screen-reader-text">Close Menu</span><span
          class="icon-close" aria-hidden="true"></span></button>
    </div><!-- .site-navigation-wrap -->
  </nav><!-- .site-navigation -->
  <button id="menu-open" class="menu-toggle"><span class="screen-reader-text">Open Menu</span><span class="icon-menu" aria-hidden="true"></span></button>
</header>




      <main class="main-content fadeInDown delay_075s">

  <article class="post">
    <header class="post-header">
      <time class="post-date" datetime="2019-10-15">October 15, 2019</time>
      <h1 class="post-title">[Paper Presentation] Stacked Autoencoder Based Deep Random Vector Functional Link Neural Network for Classification</h1>
      <div class="post-meta">
        By <span class="post-author">Mohamed BEN HAMDOUNE</span><span class="post-tags"> in <a href="/tags/#Stacked+Autoencoder" rel="tag">Stacked Autoencoder</a>, <a href="/tags/#Random+Vector+Functional+Link" rel="tag">Random Vector Functional Link</a>, <a href="/tags/#Extreme+Learning+Machine" rel="tag">Extreme Learning Machine</a></span>
      </div><!-- .post-meta -->
      
      <figure class="post-thumbnail image-card width-wide">
        <img src="https://ars.els-cdn.com/content/image/1-s2.0-S1568494619306350-gr3.jpg" alt="[Paper Presentation] Stacked Autoencoder Based Deep Random Vector Functional Link Neural Network for Classification">
      </figure><!-- .post-thumbnail -->
      
    </header><!-- .post-header -->
    <div class="post-content">
      <p><em>Presentation of a Paper avalaible <a href="https://arxiv.org/pdf/1909.12939.pdf">here</a></em>:</p>

<p>The article presents an approach to the major problems of learning metrics on the search for similarities in the case of image data sets. The authors present a method called a weakly supervised adaptrive triplet loss (ATL) that can capture fine-grained semantic similarity.
Itâ€™s written by Xiaonan Zthao, Hian Qi, Rui Luo and Larry Davis from Amazon R&amp;D.
<!--more--></p>

<h5 id="introduction">Introduction</h5>
<p>In this paper, they apply different distance metric learning on fashion datasets. We can cite a well-known named DeepFashion that contains over 800,000 diverse fashion images ranging from well-posed shop images to unconstrained consumer photos and it is annotated with rich information of clothing items. Each image in this dataset is labeled with 50 categories, 1,000 descriptive attributes, bounding box and clothing landmarks.</p>

<p><img src="http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion/attributes.jpg" alt="" /></p>

<p>A lot of approaches exist like contrastive loss where it produce a high loss (a penalty) when predicted distance is large when two object are similar and a low loss when the predicted distance is small, and vice versa for the case when the objects are different. Then we have triplet loss where a baseline (anchor) input is compared to a positive (truthy) input and a negative (falsy) input. The distance from the baseline (anchor) input to the positive (truthy) input is minimized, and the distance from the baseline (anchor) input to the negative (falsy) input is maximized. In other word, in triplet loss training a triplet contains two images belonging to the same class, referred to as the anchor and positive samples, and a thirs image, from a different class, which is referred to as the negative sample.</p>

\[d(a,p)-d(a,n)+m\]

<p>where a,p and n are anchor, positive and negtive samples, respectively \(d(.,.)\) is the learned metric function and \(m\) is a margin term which encourages the negative sample to be further from the nachor than the positive sample. As they write in their paper, DNN base trimplet loss training commonly uses stochastic gradient decent on mini batches.</p>

<h6 id="what-do-they-propose">What do they propose</h6>

<p>Deep metric learning algorithms fail to learn distances that capture fined-grained sub-categories. Such fine-grained visual similarity distances are important to learn generalized visual features and to have robust performance on cross-domain data. So they construct an embedding of the product with text product production and use this to drive an adaptive triplet loss.</p>

<h5 id="method">Method</h5>

<p>They dataset is composed with images and textual description in the form of natural language or a set of key words.
During the training, they transform images into unit vector by defining the mini-batch weakly</p>

<h5 id="result">Result</h5>

<h5 id="discussion">Discussion</h5>

    </div><!-- .post-content -->
    <div class="post-share">
      <span>Share:</span>
      <a target="_blank"
        href="https://twitter.com/intent/tweet?text=[Paper%20Presentation]%20Stacked%20Autoencoder%20Based%20Deep%20Random%20Vector%20Functional%20Link%20Neural%20Network%20for%20Classification&amp;url=http://localhost:4000/stacked-autoencoder-deep-random-vector" rel="noopener">Twitter</a>
      <a target="_blank"
        href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/stacked-autoencoder-deep-random-vector&amp;t=[Paper%20Presentation]%20Stacked%20Autoencoder%20Based%20Deep%20Random%20Vector%20Functional%20Link%20Neural%20Network%20for%20Classification" rel="noopener">Facebook</a>
    </div><!-- .share-post -->
    <div class="author-box">
      
      <div class="author-avatar" style="background-image: url('/images/author.png')"><span class="screen-reader-text">Mohamed BEN HAMDOUNE's Picture</span></div>
      
      <div class="author-details">
        <h2 class="author-title">About Mohamed BEN HAMDOUNE</h2>
        <div class="author-bio"><p>Mohamed is a Data Scientist working at Zifo RnD Solutions.</p>
</div>
        
        <span class="author-location">Cmabridge, United Kingdom</span>
        
        
        <span class="author-website"><a href="https://mbenhamd.github.io/" target="_blank" rel="noopener">https://mbenhamd.github.io/</a></span>
        
      </div><!-- .author-details -->
    </div><!-- .author-box -->
  </article><!-- .post -->

  
    <div class="comments-area">
  <div class="comments-inner">
    <h2 class="comments-title">Comments</h2>
    <div id="disqus_thread"></div>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by
        Disqus</a>.</noscript>
  </div><!-- .comments-inner -->
</div><!-- .comments-area -->

<script type="text/javascript">
  var disqus_shortname = 'justgoodthemes';
  var disqus_developer = 0;
  (function () {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>
  

</main><!-- .main-content -->
      <footer class="site-footer">
  <div class="offsite-links">
    
      
<a href="https://twitter.com/mbenhamdtw" target="_blank" rel="noopener">
  <span class="fa-twitter" aria-hidden="true"></span>
  <span class="screen-reader-text">Twitter</span>
</a>

<a href="https://github.com/mbenhamd" target="_blank" rel="noopener">
  <span class="fa-github" aria-hidden="true"></span>
  <span class="screen-reader-text">GitHub</span>
</a>

<a href="https://www.linkedin.com/in/mohamed-ben-hamdoune-73197392/" target="_blank" rel="noopener">
  <span class="fa-linkedin" aria-hidden="true"></span>
  <span class="screen-reader-text">LinkedIn</span>
</a>

    
  </div><!-- .offsite-links -->
  <div class="footer-bottom">
    <div class="site-info">
      <p>Artificial Mind Blog. Jekyll Theme Forked <a href="https://github.com/JustGoodThemes/Scriptor-Jekyll-Theme">Here</a>.</p>

    </div><!-- .site-info -->
    <a href="#page" id="back-to-top" class="back-to-top"><span class="screen-reader-text">Back to the top </span>&#8593;</a>
  </div><!-- .footer-bottom -->
</footer><!-- .site-footer -->

    </div><!-- .inner -->
  </div><!-- .site -->

  <!-- Scripts -->
  <script src="/assets/js/plugins.js"></script>
  <script src="/assets/js/custom.js"></script>

</body>
</html>
