<!DOCTYPE html>
<html lang="en-US">
<head>
  <meta name="google-site-verification" content="jk_P6ub99gOREVqLFGd54Xe1Dgp57gAS248_qlRzIJg" />
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Stacked Autoencoder Based Deep Random Vector Functional Link Neural Network for Classification</title>
  <meta name="description" content="Extreme learning machine (ELM), which can be viewed as a variant of Random Vector Functional Link (RVFL) network without the input-output direct connections,...">
  <link rel="canonical" href="http://localhost:4000/stacked-autoencoder-deep-random-vector">
  <link rel="alternate" type="application/rss+xml" title="Artificial Mind Blog. Feed"
    href="http://localhost:4000/feed.xml">
  
  <!-- Styles -->
  <link href="https://fonts.googleapis.com/css?family=Lato:400,400i,700,700i%7CNoto+Serif:400,400i,700,700i&display=swap" rel="stylesheet">
  <link href="/assets/css/style.css" rel="stylesheet">
  <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Stacked Autoencoder Based Deep Random Vector Functional Link Neural Network for Classification | Artificial Mind Blog.</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Stacked Autoencoder Based Deep Random Vector Functional Link Neural Network for Classification" />
<meta name="author" content="Mohamed BEN HAMDOUNE" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Extreme learning machine (ELM), which can be viewed as a variant of Random Vector Functional Link (RVFL) network without the input-output direct connections, has been extensively used to create multi-layer (deep) neural networks. Such networks employ randomization based autoencoders (AE) for unsupervised feature extraction followed by an ELM classifier for final decision making." />
<meta property="og:description" content="Extreme learning machine (ELM), which can be viewed as a variant of Random Vector Functional Link (RVFL) network without the input-output direct connections, has been extensively used to create multi-layer (deep) neural networks. Such networks employ randomization based autoencoders (AE) for unsupervised feature extraction followed by an ELM classifier for final decision making." />
<link rel="canonical" href="http://localhost:4000/stacked-autoencoder-deep-random-vector" />
<meta property="og:url" content="http://localhost:4000/stacked-autoencoder-deep-random-vector" />
<meta property="og:site_name" content="Artificial Mind Blog." />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-10-15T00:00:00+01:00" />
<meta name="google-site-verification" content="jk_P6ub99gOREVqLFGd54Xe1Dgp57gAS248_qlRzIJg" />
<script type="application/ld+json">
{"@type":"BlogPosting","url":"http://localhost:4000/stacked-autoencoder-deep-random-vector","headline":"Stacked Autoencoder Based Deep Random Vector Functional Link Neural Network for Classification","dateModified":"2019-10-15T00:00:00+01:00","datePublished":"2019-10-15T00:00:00+01:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/stacked-autoencoder-deep-random-vector"},"author":{"@type":"Person","name":"Mohamed BEN HAMDOUNE"},"description":"Extreme learning machine (ELM), which can be viewed as a variant of Random Vector Functional Link (RVFL) network without the input-output direct connections, has been extensively used to create multi-layer (deep) neural networks. Such networks employ randomization based autoencoders (AE) for unsupervised feature extraction followed by an ELM classifier for final decision making.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

</head>
<body>

  <div id="page" class="site">
    <div class="inner">
      <header class="site-header">
  
  <p class="site-title"><a class="logo-text" href="/">Artificial Mind Blog.</a></p>
  
  <nav class="site-navigation">
    <div class="site-navigation-wrap">
      <h2 class="screen-reader-text">Main navigation</h2>
      <ul class="menu">
        
        
        
        <li class="menu-item ">
          <a class="" href="/">Home</a>
        </li>
        
        
        
        <li class="menu-item ">
          <a class="" href="/curriculum-vitae/">Curriculum Vitae</a>
        </li>
        
        
        
        <li class="menu-item ">
          <a class="" href="/tags/">Archive</a>
        </li>
        
        
        
        <li class="menu-item ">
          <a class="" href="/about/">About</a>
        </li>
        
      </ul><!-- .menu -->
      <button id="menu-close" class="menu-toggle"><span class="screen-reader-text">Close Menu</span><span
          class="icon-close" aria-hidden="true"></span></button>
    </div><!-- .site-navigation-wrap -->
  </nav><!-- .site-navigation -->
  <button id="menu-open" class="menu-toggle"><span class="screen-reader-text">Open Menu</span><span class="icon-menu" aria-hidden="true"></span></button>
</header>




      <main class="main-content fadeInDown delay_075s">

  <article class="post">
    <header class="post-header">
      <time class="post-date" datetime="2019-10-15">October 15, 2019</time>
      <h1 class="post-title">Stacked Autoencoder Based Deep Random Vector Functional Link Neural Network for Classification</h1>
      <div class="post-meta">
        By <span class="post-author">Mohamed BEN HAMDOUNE</span><span class="post-tags"> in <a href="/tags/#Stacked+Autoencoder" rel="tag">Stacked Autoencoder</a>, <a href="/tags/#Random+Vector+Functional+Link" rel="tag">Random Vector Functional Link</a>, <a href="/tags/#Extreme+Learning+Machine" rel="tag">Extreme Learning Machine</a>, <a href="/tags/#Deep+Learning" rel="tag">Deep Learning</a></span>
      </div><!-- .post-meta -->
      
      <figure class="post-thumbnail image-card width-wide">
        <img src="https://ars.els-cdn.com/content/image/1-s2.0-S1568494619306350-gr3.jpg" alt="Stacked Autoencoder Based Deep Random Vector Functional Link Neural Network for Classification">
      </figure><!-- .post-thumbnail -->
      
    </header><!-- .post-header -->
    <div class="post-content">
      <p><em>Presentation of a Paper avalaible <a href="https://arxiv.org/pdf/1910.01858.pdf">here</a></em>:</p>

<p>Extreme learning machine (ELM), which can be viewed as a variant of Random Vector Functional Link (RVFL) network without the input-output direct connections, has been extensively used to create multi-layer (deep) neural networks.
Such networks employ randomization based autoencoders (AE) for unsupervised feature extraction followed by an ELM classifier for final decision making. Each randomization based AE acts as an independent feature extractor and a deep network is obtained by stacking several such AEs. Inspired by the better performance of RVFL over ELM, in this paper, we propose several deep RVFL variants by utilizing the framework of stacked autoencoders. Specifically, we introduce direct connections (feature reuse) from preceding layers to the fore layers of the network as in the original RVFL network. Such connections help to regularize the randomization and also reduce the model complexity. Furthermore, we also introduce denoising criterion, recovering clean inputs from their corrupted versions, in the autoencoders to achieve better higher level representations than the ordinary autoencoders. Extensive experiments on several classification datasets show that our proposed deep networks achieve overall better and faster generalization than the other relevant state-of-the-art deep neural networks.
<!--more--></p>

<h5 id="introduction">Introduction</h5>
<p>Deep or multi-layer neural network has become a popular machine learning
method in recent years. From image classification to action recognition to many other tasks, deep neural networks (DNNs) are ubiquitously used [1]. The power
of deep learning, also known as representational learning, stems from its meaningful feature extraction capabilities via multiple hidden layers [2]. Deep neural
networks are successful because they can extract complex structures and build
an internal representation from several hidden layers [3]. One among many
techniques of creating a deep neural network is based on an autoencoder (AE).
Multiple AEs are stacked together to create a deep neural network. The AE
performs meaningful feature extraction and thus, used as a building block to
create a deep neural network [4].</p>

<h6 id="what-do-they-propose">What do they propose</h6>

<p>In this section, we discuss the fundamentals of RVFL, ELM as a variant
of RVFL, Kernel ELM, autoencoder (AE) and denoising autoencoder (DAE).
To facilitate the understanding of how AEs (or DAEs) are used to build multilayer neural networks, we briefly review the concepts of Stacked AE (SAE) and
Stacked DAE (SDA). We also present a detailed review of ELM based multilayer neural networks.</p>

<h5 id="method">Method</h5>

<p>They dataset is composed with images and textual description in the form of natural language or a set of key words.
During the training, they transform images into unit vector by defining the mini-batch weakly</p>

    </div><!-- .post-content -->
    <div class="post-share">
      <span>Share:</span>
      <a target="_blank"
        href="https://twitter.com/intent/tweet?text=Stacked%20Autoencoder%20Based%20Deep%20Random%20Vector%20Functional%20Link%20Neural%20Network%20for%20Classification&amp;url=http://localhost:4000/stacked-autoencoder-deep-random-vector" rel="noopener">Twitter</a>
      <a target="_blank"
        href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/stacked-autoencoder-deep-random-vector&amp;t=Stacked%20Autoencoder%20Based%20Deep%20Random%20Vector%20Functional%20Link%20Neural%20Network%20for%20Classification" rel="noopener">Facebook</a>
    </div><!-- .share-post -->
    <div class="author-box">
      
      <div class="author-avatar" style="background-image: url('/images/author.png')"><span class="screen-reader-text">Mohamed BEN HAMDOUNE's Picture</span></div>
      
      <div class="author-details">
        <h2 class="author-title">About Mohamed BEN HAMDOUNE</h2>
        <div class="author-bio"><p>Mohamed is a Data Scientist working at Zifo RnD Solutions.</p>
</div>
        
        <span class="author-location">Cmabridge, United Kingdom</span>
        
        
        <span class="author-website"><a href="https://mbenhamd.github.io/" target="_blank" rel="noopener">https://mbenhamd.github.io/</a></span>
        
      </div><!-- .author-details -->
    </div><!-- .author-box -->
  </article><!-- .post -->

  
    <div class="comments-area">
  <div class="comments-inner">
    <h2 class="comments-title">Comments</h2>
    <div id="disqus_thread"></div>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by
        Disqus</a>.</noscript>
  </div><!-- .comments-inner -->
</div><!-- .comments-area -->

<script type="text/javascript">
  var disqus_shortname = 'justgoodthemes';
  var disqus_developer = 0;
  (function () {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>
  
  <!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-T8VZJBT');</script>
<!-- End Google Tag Manager -->
  <!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8VZJBT"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
</main><!-- .main-content -->
      <footer class="site-footer">
  <div class="offsite-links">
    
      
<a href="https://twitter.com/mbenhamdtw" target="_blank" rel="noopener">
  <span class="fa-twitter" aria-hidden="true"></span>
  <span class="screen-reader-text">Twitter</span>
</a>

<a href="https://github.com/mbenhamd" target="_blank" rel="noopener">
  <span class="fa-github" aria-hidden="true"></span>
  <span class="screen-reader-text">GitHub</span>
</a>

<a href="https://www.linkedin.com/in/mohamed-ben-hamdoune-73197392/" target="_blank" rel="noopener">
  <span class="fa-linkedin" aria-hidden="true"></span>
  <span class="screen-reader-text">LinkedIn</span>
</a>

    
  </div><!-- .offsite-links -->
  <div class="footer-bottom">
    <div class="site-info">
      <p>Artificial Mind Blog. Jekyll Theme Forked <a href="https://github.com/JustGoodThemes/Scriptor-Jekyll-Theme">Here</a>.</p>

    </div><!-- .site-info -->
    <a href="#page" id="back-to-top" class="back-to-top"><span class="screen-reader-text">Back to the top </span>&#8593;</a>
  </div><!-- .footer-bottom -->
</footer><!-- .site-footer -->

    </div><!-- .inner -->
  </div><!-- .site -->

  <!-- Scripts -->
  <script src="/assets/js/plugins.js"></script>
  <script src="/assets/js/custom.js"></script>
  <!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-T8VZJBT');</script>
<!-- End Google Tag Manager -->
  <!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8VZJBT"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
</body>
</html>
